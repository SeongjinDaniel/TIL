# 15주차 질문 & 답변



인강 (218 ~ 243)



#### 1. **Design a Kubernetes Cluster**

- GCP의 클러스터, Azure의 AWS 또는 AKS. 에 대해 이야기하자

  생산 수준 클러스터. 프로덕션 등급 애플리케이션 호스팅용.

  여러 마스터 노드가 있는 고가용성 다중 노드 클러스터가 권장됩니다.

  

  Google Container 엔진을 사용하면 GCP에서 Kubernetes 클러스터를 매우 쉽게 프로비저닝할 수 있습니다.

#### 2. **Choosing Kubernetes Infrastructure**

- 그렇다면 로컬 머신에서 kubernetes를 쉽게 시작하는 데 사용할 수 있는 솔루션에는 어떤 것이 있습니까?

  Minikube는 단일 노드 클러스터를 쉽게 배포합니다. Oracle과 같은 가상화 소프트웨어 중 하나에 의존합니다.

- TurnKey Solutions

  - OpenShift
  - Cloud Foundry Container Runtime
  - VMware Cloud PKS
  - Vagrant

- Hosted Solutions

  - Google Container Engine(GKE)
  - OpenShift Online
  - Azure Kubernetes Service
  - Amazon Elastic Container Service for Kubernetes(EKS)

TurnKey와 Hosted  Solution에서 장단점을 찾아보진 않았지만 가장 선호하는 것은 설문조사를 기반하여 VirtualBox를 사용하는 것이라고 강의에서 알려줌. (Master Node를 나의 컴퓨터로하고 Worker Node를 VirtualBox를 사용)

#### 3. **Configure High Availability**

**API Server**가 요청을 수신하고 처리하거나 정보를 제공하는 책임이 있다.

- 모든 클러스터 노드의 API 서버는 동시에 활성 상태로 실행될 수 있다.
- kubectl 유틸리티가 작업을 완료하기 위해 API 서버와 통신한다.
- API 서버가 수신 대기하는 곳이며 kube-config 파일에서 구성된다.

**Controller Manager**

- 클러스터의 상태를 보고 조치를 취하는 컨트롤러이다.

- 프로세스

  > 기본적으로 true로 설정된 리더 선택 옵션을 지정할 수 있습니다.
  >
  > 이 옵션을 사용하면 컨트롤러 관리자 프로세스가 시작될 때 임대 또는 잠금을 얻으려고 시도합니다.
  >
  > kube-controller-manager 끝점으로 명명된 kubernetes의 끝점 개체입니다. 어느 것이 먼저 처리되는지
  >
  > 끝점을 업데이트합니다.
  >
  > 이 정보로 임대를 얻고 둘 중 활성이 됩니다.
  >
  > 다른 하나는 소극적 상태가 되어 Leader-elect-lease-를 사용하여 지정된 임대 기간 동안 잠금을 유지합니다.
  >
  > 지속 시간 옵션은 기본적으로 15초로 설정됩니다.
  >
  > 그런 다음 활성 프로세스는 옵션의 기본값인 10초마다 임대를 갱신합니다.
  >
  > 지도자 당선자 갱신 기한. 두 프로세스 모두 2초마다 리더가 되려고 시도합니다.
  >
  > Leader-elect-retry-period 옵션.
  >
  > 그런 식으로 한 프로세스가 실패하면 첫 번째 충돌이 필요하기 때문에 두 번째 프로세스가 획득할 수 있습니다.
  >
  > 자물쇠를 채우고 리더가 됩니다. 스케줄러는 유사한 접근 방식을 따르고 동일한 명령줄을 사용합니다.

**Scheuler**

- Controller Manager는 지속적으로 상태를 감시하는 복제 컨트롤러와 같은 컨트롤러로 구성된다.
- 새로운 POD 생성과 같은 필요한 조치를 취한다.
- 하나가 실패할 때. 여러 인스턴스가 병렬로 실행되면 작업이 중복될 수 있다.(병렬로 실행 X), 스케줄러도 마찬가지이다.

**ETCD**

- 2가지 토폴로지 구성

  > 하나는 여기에서 보이는 것과 동일한 아키텍처이며 이 과정을 통해 따라왔습니다.
  >
  > ETCD는 kubernetes 마스터 노드의 일부입니다. 이를 스택형 제어 계획 노드 토폴로지라고 합니다.
  >
  > 이것은 설정하기 쉽고 관리하기 쉽습니다. 그리고 더 적은 수의 노드가 필요합니다. 그러나 하나의 노드가 다운되면
  >
  > ETCD 구성원과 제어 평면 인스턴스가 모두 손실되고 중복성이 손상됩니다. 

  > 여기서 ETCD는 제어 평면 노드와 분리되어 자체 서버 집합에서 실행됩니다. 이것은 토폴로지입니다.
  >
  > 외부 ETCD 서버와. 이전 토폴로지와 비교
  >
  > 고장난 컨트롤 플레인 노드가 ETCD 클러스터 및 저장하는 데이터에 영향을 미치지 않기 때문에 이는 덜 위험합니다.
  >
  > 그러나 설정이 더 어렵고 외부 etcd 노드에 대해 두 배의 서버가 필요합니다. 그래서
  >
  > API 서버는 ETCD 서버와 통신하는 유일한 구성 요소입니다.
  >
  > API 서비스 구성 옵션, ETCD 서버의 위치를 지정하는 옵션 세트가 있습니다.
  >
  > 따라서 우리가 사용하는 토폴로지와 ETCD 서버를 구성하는 위치에 관계없이 동일한 서버의 날씨
  >
  > 또는 별도의 서버에서.
  >
  > 궁극적으로 우리는 API 서버가 ETCD 서버의 올바른 주소를 가리키고 있는지 확인해야 합니다.
  >
  > 이제 ETCD는 분산 시스템이므로 API 서버 또는 통신하려는 기타 구성 요소를 기억하십시오.
  >
  > 모든 인스턴스에서 ETCD 서버에 연결할 수 있습니다.
  >
  > 사용 가능한 ETCD 서버 인스턴스를 통해 데이터를 읽고 쓸 수 있습니다.
  >
  > 이것이 kube-apiserver 구성에서 etcd-servers 목록을 지정하는 이유입니다.

#### 4. **ETCD In HA**

- 키, 값 으로 구성되어 있다.

- 모든 데이터를 읽을 수 있지만 쓰기의 경우는 아니다. ETCD는 각 노드의 쓰기를 동시에 처리하지 않는다. 대신 인스턴스 중 하나만 쓰기 처리를 한다. 만약 두 노드가 있다면 그 중에서 리더를 선택한다. 나머지 노드는 팔로워가 된다.

-  ETCD는 RAFT 프로토콜을 사용하여 분산 합의를 구현한다.

  > 요청을 시작하기 위한 임의의 타이머.
  >
  > 예를 들어 임의의 타이머는 타이머를 완료한 첫 번째 관리자가 보낸 세 명의 관리자에서 시작됩니다.
  >
  > 리더가 되기 위한 권한을 요청하는 다른 노드에 대한 요청을 출력합니다. 수신에 다른 관리자
  >
  > 요청은 투표로 응답하고 노드는 리더 역할을 맡습니다. 이제 선출되었으니
  >
  > 리더는 정기적으로 다른 마스터에게 계속 진행 중임을 알리는 알림을 보냅니다.
  >
  > 리더의 역할을 맡게 됩니다. 다른 노드가 리더로부터 알림을 받지 못하는 경우
  >
  > 리더가 다운되거나 네트워크 연결이 끊어져서 발생할 수 있는 특정 시점에
  >
  > 노드는 그들 사이에서 재선 과정을 시작하고 새로운 리더가 다시 식별됩니다.
  >
  > 권리가 표시되는 이전 예에서 리더에 의해 처리되고 다른 사람에게 복제됩니다.
  >
  > 클러스터의 노드는 권한이 다른 노드에 복제된 후에만 완료된 것으로 간주됩니다.

- 우리는 ETCD 클러스터가 고가용성이다. 따라서 노드를 잃어도 여전히 작동해야 한다.

- Quorum = N/2 + 1 —-> 항상 홀수

- 내결함성을 위해 필요한 최소 노드 수는 3이다.



#### 5. **Introduction to Deployment with Kubeadm**

![image](https://user-images.githubusercontent.com/55625864/139566846-3e1b30c0-37d0-4842-b103-4aed05cad23e.png)



![image](https://user-images.githubusercontent.com/55625864/139567975-34679a0f-20b1-4616-a420-fd4c767c8a21.png)



1. 시스템이 생성되면 한 노드를 마스터로 지정하고 다른 노드를 작업자 메모로 지정합니다.
2. 호스트에 컨테이너 런타임을 설치하는 것입니다. 따라서 모든 메모에 Docker를 설치해야 합니다.
3. 모든 메모에 Kube 관리 도구를 설치하는 것입니다. kubeadm tool은 자기 스스로 처리하는 것(bootstrap)을 도와줍니다.
4. 이 과정에서 마스터 서버를 초기화하는 것입니다. 모든 필수 구성 요소는 마스터 서버에 설치 및 구성됩니다. 마스터가 초기화되고 작업자 메모를 마스터에 결합하기 전에 다음을 확인해야 합니다. 네트워크 전제 조건이 충족되고 시스템 간의 정상적인 네트워크 연결이 충분하지 않습니다. 이를 위해서는 마스터 노드와 작업자 노드 사이에 특별한 네트워킹 솔루션이 필요합니다. 이것은 POD 네트워크입니다.
5. 마지막 단계는 Worker 노드에 합류하는 것입니다. 마스터 노드를 참고합니다.

이제 환경으로 캐비닛에서 애플리케이션을 시작하도록 설정완료.



#### 6. **Deploy with Kubeadm - Provision VMs with Vagrant**

#### 7. **Demo - Deployment with Kubeadm**

1. iptables가 브리지된 트래픽을 보게 하기
2.  컨테이너 런타임(도커)
3. Creating a cluster with kubeadm
4. pod 네트워크를 클러스터에 배포(Weave를 pod 네트워크 솔루션으로 사용)

```
$ kubeadm init --pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address=[eth0 inet address]
$ logout
# kubeadm 실행하면 아래 와같이 실행하라고 문구나옴
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/ .kube/config
$ sudo chown $(id -u):$(id -g) $HOME/ .kube/config

$...
```

구성 파일이 아닌 관리자가 캐비닛에 액세스하는 데 필요한 정보와 자격 증명을 가지고 있습니다.

Weave 사용

#### 8. End to End Section –> 2020년 9월부터 시험에서 제외

- 공부하고 싶다면 아래주소에서 확인

  https://www.youtube.com/watch?v=-ovJrIIED88&list=PL2We04F3Y_41jYdadX55fdJplDvgNGENo&index=18

#### 9. **Troubleshooting**

**Application Failure**



**ControlPlane Error TroubleShooting**

- `kubectl get pods -n kube-system`
  - 도구를 사용하여 kube-system 네임스페이스의 포드가 실행 중인지 확인할 수 있다.

컨트롤 플레인 구성 요소가 우리의 경우와 같이 서비스로 배포되면 상태를 확인.

- `service kube-apiserver status`
- `service kube-controller-manager status`
- `service kube-scheduler status`
- `service kubelet status`
- `service kube-proxy status`

Check Service Logs

- `kubectl logs kube-apiserver-master -n kube-system`
- `sudo journalctl -u kube-apiserver`
- 







---

---

---

15주차 (2021-10-31 22:00)
**Design & Install a k8s cluster**
베스트 프랙티스?

workload를 마스터에 부여하지 않기 (특히 운영환경에서)

**HA (High Availability) Configuration for Master Node**	

= 같은 컴포넌트를 가진 마스터 노드를 추가로 둔다. (예비용?)	

= active/standby 세팅을 통해 똑같은 마스터 노드가 동시에 운영되지 않도록 컨트롤가능	

= passive/active를 결정하는 것은 leader election
ETCD

distributed key-value store	

= 여러 개의 ETCD 서버(or 클러스터?)로 구성	

= 하나에 장애가 나도 정상적으로 운영가능

**데이터의 정합성을 유지하는 법?**	

= leader & followers

요청이 들어오면, 일단 리더에게 보낸다. 리더가 명령을 처리한 후, 팔로워들이 같은 copy를 가지도록 한다.

같은 처리를 마친 팔로워들이 리더에게 consent를 보낸다.	

**leader election process**

random timer 가 돈다.

첫 번째로 타이머를 처리한 노드가 다른 노드들에게 리더가 되겠다는 허가요청을 보낸다.

해당 요청을 받은 노드들이 표로 응답한다.

**다수(majoirty)가 처리에 성공해야 write operation이 성공했다고 본다.**

**다수를 구하는 방법 (Quorum)**	

= N/2 + 1 = majority	

= minimal 3	

= 짝수개의 노드는 권장되지 않는다.

```a random timer is kicked off on the three managers.then, the first one to finish the timer sends out a request to the other nodes requesting a permission to be the leaderthe other managers receiving the request responses with their votesin case the other nodes do not receive any notification at any point in time, they initiate the leader election processa write operation is considered successful when the majority manages to get it.```

**설치 전략**

1. stacked topology

   = 클러스터 내부에 ETCD를 두는 것

   = 설치 및 관리가 용이하고, 더 적은 노드가 필요하다= 장애 시 더 위험

2. external etcd topology	

   = 위의 장단점을 뒤집으면 된다.



**Trouble Shooting**

= 요기는 저도 문제를 제대로 다 못풀어서, 같이 풀어보면 좋을 것 같습니다.
인강에서 준 Tip(?)

= root cause 찾을 때까지 모든 오브젝트 and 연결고리 살펴보래요

**Application** 

1. check if the web server is accessible
   ex. curl 로 요청보내보기

2. check the service
   ex. 포드랑 endpoint 가 잘 연결되어 있는가
   ex. selector가 잘 지정되어 있는가

3. 포드 살펴보기 ex. 어떤 state에 있는지
   ex. restart 횟수도 살펴보기

   ex. describe/log 활용
   	(kubectl describe pod ~, kubectl logs -f ~ = watch)	

   or kubectl logs ~ -f --previous = logs for a previous pod	

   자세한 내용은 공식문서 보래요 

   https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/

**controlplane**

1. node 상태 살펴보기

2. controlplane 내부 포드 살펴보기

3. controlplane 서비스 살펴보기

   ex.	

   service kube-apiserver status

   service kube-controller-manager status

   service kube-scheduler status

   service kubelet status

   service kube-proxy status

4. service 로그 살펴보기	

   kubectl logs kube-apiserver-master -n kube-system

   sudo journalctl -u kube-apiserver
   공식문서 보세요 래요

   https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/

   **Worker node failure**

   1. 노드 상태를 먼저 살펴보자

   describe? 로 찍어봤을 때 아래와 같은 조건들이 나올 수 있다.

   true, false, unknown

   - out of disk = out of disk space (non-sufficient)
   - memory pressure = out of memory
   - disk pressure = low disk capacity (then disk pressure vs out of disk)
   - pid pressure = too many processes
   - ready = a node is fully healthy

   2. last heartbeat time을 살펴보는 것도 도움이 된다고 한다.

      = 노드가 언제 사망했는지 알려준다. 

      = 언제 워커노드가 마스터노드와의 통신을 멈췄는지

      = 이때 상태는 unknown으로 바뀜

      top, df- h
       = (top) - cpu, memory, (df -h) - disk

   4. kubelet 상태를 살펴보자	

      = service kubelet status
      = sudo journalctl -u kubelet

   5. kubelet certificates도 봐야한다.

      = 만료되지는 않았는지? 올바른 그룹에 속해있는지, 올바른 CA에 의해 발행됬는지 등

   **Network TroubleShooting**(요기가 젤 어렵더라고요)

   [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/*](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)

   **CoreDNS in pending state**

   1. 플러그인 설치 잘 되어있는지 확인

      = k8s는 네트워크 세팅을 위해 CNI plugin을 사용한다고 한다.

      = 그리고 kubelet이 plugin을 실행한다.

      = 위에 링크에 들어가보면 설치법이 있다.

   CoreDNS in CrashLoopBackOff or Error state

   1. 도커 버전을 업그레이드 하는 것도 있었음

   2. disable SELinux(?)

   3. `allowPrivilegeEscalation` = true

      (coredns deployment 세팅인듯)

   4. loop가 있으면 요 상태가 된다고도 하네요

      (Another cause for CoreDNS to have CrashLoopBackOff is when a CoreDNS Pod deployed in Kubernetes detects a loop.)

      이외에도

   

   with Kube-Proxy
   a quick reminder

   Kube Proxy?

   1. 클러스터의 각 노드에서 동작하는 네트워크 프록시 = DaemonSet
   2. 노드의 네트워크 규칙을 관리한다
   3. service, endpoint를 watch 
   4. 실제 포드로 트래픽을 보낸다 (클라이언트가 서비스로 연결했을 때)

   Troubleshooting with Kube Proxy

   1. kube-system namespace 내의 kube-proxy가 running 상태인지
   2. Check **kube-proxy** logs.
   3. kube proxy에 사용되는 configmap이 잘 설정되었는지
      \+ configmap 에 kube-config가 정의되어 있는지
   4. 컨테이너 내의 kube-proxy가 running 상태인지

   도움이 될 만한 명령어?kubectl describe ds kube-proxy -n kube-system

   netstat -plan | grep kube-proxy

   https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/

   https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/

   