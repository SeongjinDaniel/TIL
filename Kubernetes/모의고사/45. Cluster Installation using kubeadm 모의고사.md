# 45. Cluster Installation using kubeadm 모의고사



1. Install the `kubeadm` package on the `controlplane` and `node01`. Use the exact version of `1.21.0-00`

   - kubeadm installed on controlplane ?
   - Kubeadm installed on worker node01

   **Hint**

   - https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

2. What is the version of `kubelet` installed?

   **Hint**

   - Run: `kubelet --version` on the `controlplane` node.

3. How many nodes are part of kubernetes cluster currently?

   Are you able to run `kubectl get nodes`?

   ```
   $ kubectl get nodes
   ```

4. Lets now bootstrap a `kubernetes` cluster using `kubeadm`.

   The latest version of Kubernetes will be installed.

5. Initialize `Control Plane Node (Master Node)`. Use the following options:

   1. `apiserver-advertise-address` - Use the IP address allocated to eth0 on the controlplane node
   2. `apiserver-cert-extra-sans` - Set it to `controlplane`
   3. `pod-network-cidr` - Set to `10.244.0.0/16`

   Once done, set up the `default kubeconfig` file and wait for node to be part of the cluster.

- Master node initialized

  - **Hint**

    run `kubeadm init --apiserver-cert-extra-sans=controlplane --apiserver-advertise-address 10.2.223.3 --pod-network-cidr=10.244.0.0/16`
    The IP address used here is just an example. It will change for your lab session. Make sure to check the IP address allocated to eth0 by running:

    ```sh
    root@controlplane:~# ifconfig eth0
    eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450
            inet 10.2.223.3  netmask 255.255.255.0  broadcast 10.2.222.255
            ether 02:42:0a:02:de:0a  txqueuelen 0  (Ethernet)
            RX packets 6223  bytes 769785 (769.7 KB)
            RX errors 0  dropped 0  overruns 0  frame 0
            TX packets 5913  bytes 1483419 (1.4 MB)
            TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
    
    root@controlplane:~#
    ```

    In this example, the IP address is `10.2.223.3`

  - **Solution**

    Once you run the `init command`, you should see an output similar to below:

    ```sh
    [init] Using Kubernetes version: v1.21.0
    [preflight] Running pre-flight checks
            [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
    [preflight] Pulling images required for setting up a Kubernetes cluster
    [preflight] This might take a minute or two, depending on the speed of your internet connection
    [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
    [certs] Using certificateDir folder "/etc/kubernetes/pki"
    [certs] Generating "ca" certificate and key
    [certs] Generating "apiserver" certificate and key
    [certs] apiserver serving cert is signed for DNS names [controlplane kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.2.223.3]
    [certs] Generating "apiserver-kubelet-client" certificate and key
    [certs] Generating "front-proxy-ca" certificate and key
    [certs] Generating "front-proxy-client" certificate and key
    [certs] Generating "etcd/ca" certificate and key
    [certs] Generating "etcd/server" certificate and key
    [certs] etcd/server serving cert is signed for DNS names [controlplane localhost] and IPs [10.2.223.3 127.0.0.1 ::1]
    [certs] Generating "etcd/peer" certificate and key
    [certs] etcd/peer serving cert is signed for DNS names [controlplane localhost] and IPs [10.2.223.3 127.0.0.1 ::1]
    [certs] Generating "etcd/healthcheck-client" certificate and key
    [certs] Generating "apiserver-etcd-client" certificate and key
    [certs] Generating "sa" key and public key
    [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
    [kubeconfig] Writing "admin.conf" kubeconfig file
    [kubeconfig] Writing "kubelet.conf" kubeconfig file
    [kubeconfig] Writing "controller-manager.conf" kubeconfig file
    [kubeconfig] Writing "scheduler.conf" kubeconfig file
    [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
    [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
    [kubelet-start] Starting the kubelet
    [control-plane] Using manifest folder "/etc/kubernetes/manifests"
    [control-plane] Creating static Pod manifest for "kube-apiserver"
    [control-plane] Creating static Pod manifest for "kube-controller-manager"
    [control-plane] Creating static Pod manifest for "kube-scheduler"
    [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
    [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
    [kubelet-check] Initial timeout of 40s passed.
    [apiclient] All control plane components are healthy after 85.004816 seconds
    [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
    [kubelet] Creating a ConfigMap "kubelet-config-1.21" in namespace kube-system with the configuration for the kubelets in the cluster
    [upload-certs] Skipping phase. Please see --upload-certs
    [mark-control-plane] Marking the node controlplane as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
    [mark-control-plane] Marking the node controlplane as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
    [bootstrap-token] Using token: gtmdad.olx54xrbafcionbd
    [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
    [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
    [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
    [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
    [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
    [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
    [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
    [addons] Applied essential addon: CoreDNS
    [addons] Applied essential addon: kube-proxy
    
    Your Kubernetes control-plane has initialized successfully!
    
    To start using your cluster, you need to run the following as a regular user:
    
      mkdir -p $HOME/.kube
      sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
      sudo chown $(id -u):$(id -g) $HOME/.kube/config
    
    Alternatively, if you are the root user, you can run:
    
      export KUBECONFIG=/etc/kubernetes/admin.conf
    
    You should now deploy a pod network to the cluster.
    Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
      https://kubernetes.io/docs/concepts/cluster-administration/addons/
    
    Then you can join any number of worker nodes by running the following on each as root:
    
    kubeadm join 10.2.223.3:6443 --token gtmdad.olx54xrbafcionbd \
            --discovery-token-ca-cert-hash sha256:fb08c01c782ef1d1ad0b643b56c9edd6a864b87cff56e7ff35713cd666659ff4 
    ```

    Once the command has been run successfully, set up the kubeconfig:

    ```sh
    root@controlplane:~# mkdir -p $HOME/.kube
    root@controlplane:~#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    root@controlplane:~#   sudo chown $(id -u):$(id -g) $HOME/.kube/config
    root@controlplane:~# `
    ```

  ```
  $ kubeadm init --pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address=[eth0 inet address]
  ```

  위 솔루션 대로 했더니 에러…… 아래와 같이 해서 해결함
  
  ```
  sudo mkdir /etc/docker
  cat <<EOF | sudo tee /etc/docker/daemon.json
  {
    "exec-opts": ["native.cgroupdriver=systemd"],
    "log-driver": "json-file",
    "log-opts": {
      "max-size": "100m"
    },
    "storage-driver": "overlay2"
  }
  EOF
  ```
  
  상기 문구 실행 후 
  
  ```
  sudo systemctl enable docker
  sudo systemctl daemon-reload
  sudo systemctl restart docker
  
  # kubelet가 실행인지 확인
  sudo systemctl status kubelet
  # 실행중이 아닐 경우
  sudo systemctl start kubelet
  ```
  
  상기내용 실행 -> kubeadm reset -> kubeadm init or join 재실행 
  
  https://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker
  
  왜인지 Check에 실패..

6. 

7. Join `node01` to the cluster using the join token

   - Node01 joined the cluster?

   **Hint**

   - Use the join token provided by the kubeadm command or create a new token.

   **Solution**

   To create token:

   ```sh
   root@controlplane:~# kubeadm token create --print-join-command
   kubeadm join 10.2.223.3:6443 --token 50pj4l.0cy7m2e1jlfmvnif --discovery-token-ca-cert-hash sha256:fb08c01c782ef1d1ad0b643b56c9edd6a864b87cff56e7ff35713cd666659ff4 
   root@controlplane:~#
   ```

   next, run the join command on `node01`:

   ```sh
   root@node01:~# kubeadm join 10.2.223.3:6443 --token 50pj4l.0cy7m2e1jlfmvnif --discovery-token-ca-cert-hash sha256:fb08c01c782ef1d1ad0b643b56c9edd6a864b87cff56e7ff35713cd666659ff4
   [preflight] Running pre-flight checks
           [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
   [preflight] Reading configuration from the cluster...
   [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
   [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
   [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
   [kubelet-start] Starting the kubelet
   [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
   
   This node has joined the cluster:
   * Certificate signing request was sent to apiserver and a response was received.
   * The Kubelet was informed of the new secure connection details.
   
   Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
   
   root@node01:~#
   ```

   5번과 같음 문제 발생. 그래서 5번과 같이 해결.

   왜인지 Check에 실패..

8. Install a Network Plugin. As a default, we will go with `flannel`

   Refer to the official documentation for the procedure

   - Network Plugin deployed?

   **Hint**

   - Install `flannel` CNI.

   **Solution**

   - On the controlplane, run: `kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml`