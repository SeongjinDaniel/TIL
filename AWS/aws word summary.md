# aws word summary

- **ELB(Elastic Load Balance)**

  - 로드 밸런서는 클라이언트에서 들어오는 트래픽을 수락하고 요청을 하나 이상의 가용 영역에있는 등록 된 대상 (예 : EC2 인스턴스)으로 라우팅합니다. 또한로드 밸런서는 등록 된 대상의 상태를 모니터링하고 정상 대상으로 만 트래픽을 라우팅하도록합니다. 로드 밸런서가 비정상 대상을 감지하면 해당 대상으로의 트래픽 라우팅을 중지합니다. 그런 다음 대상이 다시 정상 상태임을 감지하면 해당 대상에 대한 트래픽 라우팅을 재개합니다.
  
- 로드 밸런서는 프라이빗 IP를 사용하여 기본 EC2 인스턴스와 통신합니다.
  
  - Elastic Load Balancer는 Auto Scale 그룹과 연결하여 수평 적 확장을 제공 할 수 있습니다. 수직 확장성 향상 X
  
- **Auto Scaling**

  - Auto Scaling 그룹은 여러 리전에 걸쳐있을 수 없습니다.
  - Auto Scaling 그룹은 동일한 리전 내의 하나 이상의 가용 영역에 EC2 인스턴스를 포함 할 수 있습니다.

  - Amazon EC2 Auto Scaling은 Auto Scaling 그룹에 대해 활성화 된 가용 영역간에 인스턴스를 균등하게 배포하려고 시도합니다.
    - 하나의 가용 영역이 비정상이거나 사용할 수 없게되면 Auto Scaling은 영향을받지 않는 가용 영역에서 새 인스턴스를 시작합니다. 비정상 가용 영역이 정상 상태로 돌아 오면 Auto Scaling은 지정된 모든 가용 영역에 애플리케이션 인스턴스를 균등하게 자동으로 재배포합니다.
  - VPC의 Auto Scaling 그룹의 경우 EC2 인스턴스가 서브넷에서 시작됩니다.
    - VPC의 Auto Scaling 그룹의 경우 EC2 인스턴스가 서브넷에서 시작됩니다. 고객은 Auto Scaling 그룹을 생성하거나 업데이트 할 때 EC2 인스턴스의 서브넷을 선택할 수 있습니다.

- **Elastic Beanstalk**

  AWS Elastic Beanstalk는 클라우드에서 애플리케이션을 쉽게 배포하고 실행할 수있는 환경을 제공합니다. 개발자 도구와 통합되며 애플리케이션의 라이프 사이클을 관리 할 수있는 원 스톱 환경을 제공합니다.

  AWS Elastic Beanstalk를 사용하면 각 환경이 한 번에 하나의 애플리케이션 버전 만 실행하는 환경으로 애플리케이션을 실행하는 모든 리소스를 관리 할 수 있습니다. 환경이 생성 될 때 Elastic Beanstalk는 애플리케이션 버전을 실행하는 데 필요한 모든 리소스를 프로비저닝합니다. Beanstalk에서 처리하므로 서버 프로비저닝, 구성 및 배포에 대해 걱정할 필요가 없습니다.

  AWS Elastic Beanstalk는 Apache와 같은 친숙한 서버에서 Java, .NET, PHP, Node.js, Python, Ruby, Go 및 Docker로 개발 된 웹 애플리케이션 및 서비스를 배포하고 확장하기위한 사용하기 쉬운 서비스입니다. , Nginx, Passenger 및 IIS. 코드를 업로드하기 만하면 Elastic Beanstalk가 용량 프로비저닝,로드 밸런싱, 자동 확장에서 애플리케이션 상태 모니터링에 이르기까지 배포를 자동으로 처리합니다. 동시에 애플리케이션을 구동하는 AWS 리소스를 완전히 제어 할 수 있으며 언제든지 기본 리소스에 액세스 할 수 있습니다.

  - **'추가 배치로 롤링'배포 정책을 사용하여 배포** 
    - 이 방법을 사용하면 Elastic Beanstalk가 추가 인스턴스 배치를 시작한 다음 롤링 배포를 수행합니다. 추가 배치를 시작하는 데는 시간이 걸리며 배포 전반에 걸쳐 동일한 대역폭이 유지됩니다. 이 정책은 또한 롤링 방법에 비해 배포 시간이 훨씬 더 길지만 가용성 감소를 방지합니다. 마지막으로이 옵션은 배포 전반에 걸쳐 동일한 대역폭을 유지해야하는 경우에 적합합니다.
  - **'불변'배포 정책을 사용하여 배포** 
    - 기존 인스턴스를 업데이트하는 대신 새 애플리케이션 버전이 항상 새 인스턴스에 배포되도록하는 느린 배포 방법입니다. 또한 배포가 실패 할 경우 빠르고 안전한 롤백이라는 추가적인 이점이 있습니다. 이 방법을 사용하면 Elastic Beanstalk가 변경 불가능한 업데이트를 수행하여 애플리케이션을 배포합니다. 변경 불가능한 업데이트에서는 두 번째 Auto Scaling 그룹이 환경에서 시작되고 새 버전은 새 인스턴스가 상태 확인을 통과 할 때까지 이전 버전과 함께 트래픽을 제공합니다.
  - **'한 번에 모두'배포 정책을 사용하여 배포** 
    - 가장 빠른 배포 방법입니다. 짧은 서비스 손실을 받아 들일 수 있고 빠른 배포가 중요한 경우에 적합합니다. 이 방법으로 Elastic Beanstalk는 각 인스턴스에 새 애플리케이션 버전을 배포합니다. 그런 다음 웹 프록시 또는 애플리케이션 서버를 다시 시작해야 할 수 있습니다. 결과적으로 사용자가 애플리케이션을 잠시 사용할 수 없거나 가용성이 낮을 수 있습니다.
  - **'롤링'배포 정책을 사용하여 배포** 
    - 이 방법을 사용하면 애플리케이션이 한 번에 한 배치의 인스턴스 환경에 배포됩니다. 대부분의 대역폭은 배포 동안 유지됩니다. 가동 중지 시간을 방지하고 배포 시간을 늘리는 대신 가용성 감소를 최소화합니다. 서비스를 완전히 잃어버린 기간을 수용 할 수없는 경우에 적합합니다.

#### **CloudFormation**

- AWS CloudFormation은 개발자와 기업이 관련 AWS 및 타사 리소스 모음을 손쉽게 생성하고이를 질서 있고 예측 가능한 방식으로 프로비저닝 할 수있는 방법을 제공하는 서비스입니다.
  

AWS CloudFormation은 개발자와 기업이 관련 AWS 및 타사 리소스 모음을 쉽게 생성하고이를 질서 있고 예측 가능한 방식으로 프로비저닝 할 수있는 방법을 제공하는 서비스입니다. CloudFormation에서는 필요한 리소스 유형을 지정하기 위해 템플릿을 생성해야하므로이 옵션은 올바르지 않습니다.

AWS CloudFormation은 개발자와 기업이 관련 AWS 및 타사 리소스 모음을 쉽게 생성하고이를 질서 있고 예측 가능한 방식으로 프로비저닝 할 수있는 방법을 제공하는 서비스입니다. 매개 변수 유형을 통해 CloudFormation은 스택 생성 프로세스 초기에 입력을 검증 할 수 있습니다.
CloudFormation은 현재 다음 매개 변수 유형을 지원합니다.

```
String – A literal string
Number – An integer or float
List<Number> – An array of integers or floats
CommaDelimitedList – An array of literal strings that are separated by commas
AWS::EC2::KeyPair::KeyName – An Amazon EC2 key pair name
AWS::EC2::SecurityGroup::Id – A security group ID
AWS::EC2::Subnet::Id – A subnet ID
AWS::EC2::VPC::Id – A VPC ID
List<AWS::EC2::VPC::Id> – An array of VPC IDs
List<AWS::EC2::SecurityGroup::Id> – An array of security group IDs
List<AWS::EC2::Subnet::Id> – An array of subnet IDs
```

AWS CloudFormation 템플릿은 AWS 인프라를 설명하는 JSON 또는 YAML 형식의 텍스트 파일입니다. 템플릿에는 몇 가지 주요 섹션이 포함됩니다. "리소스"섹션은 유일한 필수 섹션입니다. 선택 사항 인 "Transform"섹션은 AWS CloudFormation이 템플릿을 처리하는 데 사용하는 하나 이상의 매크로를 지정합니다.

  AWS 서버리스 애플리케이션 모델 (SAM)은 서버리스 애플리케이션을 구축하기위한 오픈 소스 프레임 워크입니다. 함수, API, 데이터베이스 및 이벤트 소스 매핑을 표현하는 약식 구문을 제공합니다. 리소스 당 몇 줄만 있으면 원하는 애플리케이션을 정의하고 YAML을 사용하여 모델링 할 수 있습니다.



**AWS CloudFormation**은 스택 관리에 도움이되는 몇 가지 기본 제공 함수를 제공합니다. 내장 함수는 템플릿에서 런타임까지 사용할 수없는 속성에 값을 할당하는 데 사용됩니다.

**`!GetAtt`**- Fn :: GetAtt 내장 함수는 템플릿의 리소스에서 속성 값을 반환합니다. 이 예제 스 니펫은 논리적 이름 myELB-YML :! GetAtt myELB.DNSName JSON : "Fn :: GetAtt": [ "myELB", "DNSName"]을 사용하여로드 밸런서의 DNS 이름이 포함 된 문자열을 반환합니다.

**`!Sub`**- 내장 함수 Fn :: Sub는 입력 문자열의 변수를 사용자가 지정한 값으로 대체합니다. 템플릿에서 이 함수를 사용하여 스택을 생성하거나 업데이트 할 때까지 사용할 수 없는 값을 포함하는 명령 또는 출력을 생성 할 수 있습니다.

**`!Ref`** - 내장 함수 Ref는 지정된 매개 변수 또는 리소스의 값을 반환합니다.

**`!FindInMap`**- 내장 함수 Fn :: FindInMap은 Mappings 섹션에 선언 된 2 단계 맵의 키에 해당하는 값을 반환합니다. 예를 들어 AMI를 AWS 리전과 연결하는 단일 맵인 RegionMap이 포함 된 매핑 섹션에서이를 사용할 수 있습니다.

---

- **ECS**

- **Fargate**

- **Cognito**

- **SSL/TLS server certificates**

  > **AWS Certificate Manager(ACM)란 무엇입니까?**
  >
  > AWS Certificate Manager는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 배포할 수 있도록 지원하는 서비스입니다. SSL/TLS 인증서는 네트워크 통신을 보호하고 인터넷상에서 웹 사이트의 자격 증명과 프라이빗 네트워크상에서 리소스의 자격 증명을 설정하는 데 사용됩니다. AWS Certificate Manager는 SSL/TLS 인증서를 구매, 업로드 및 갱신하는 데 드는 시간 소모적인 수동 프로세스를 대신 처리합니다. AWS Certificate Manager에서는 사용자가 신속하게 인증서를 요청하고, Elastic Load Balancer, Amazon CloudFront 배포, API Gateway 기반 API와 같은 AWS 리소스에 배포한 후, AWS Certificate Manager가 인증서 갱신을 처리하도록 할 수 있습니다. 또한, 내부 리소스에 대한 사설 인증서를 생성하고 중앙에서 인증서 수명 주기를 관리할 수도 있습니다. AWS Certificate Manager를 통해 프로비저닝되고 ACM 통합 서비스(Elastic Load Balancing, Amazon CloudFront, Amazon API Gateway 등)에만 전용으로 사용되는 공인 및 사설 SSL/TLS 인증서는 무료입니다. 사용자는 애플리케이션을 실행하기 위해 생성한 AWS 리소스에 대한 비용을 지불합니다. 고객은 각 사설 CA의 운영에 대해 해당 CA를 삭제할 때까지 그리고 발급한 사설 인증서 중 [ACM 통합 서비스](https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html) 이외 다른 서비스에서도 사용된 인증서에 대해 월별 요금을 지불합니다.

  > **SSL/TLS 인증서란 무엇입니까?**
  >
  > SSL/TLS 인증서는 SSL/TLS(Secure Sockets Layer/전송 계층 보안) 프로토콜을 사용하여 웹 브라우저가 웹 사이트에 대해 암호화된 네트워크 연결을 확인하고 설정할 수 있게 해줍니다. 인증서는 퍼블릭 키 인프라(PKI)로 알려진 암호화 시스템 내에서 사용됩니다. 양쪽 모두가 인증 기관으로 알려진 타사를 신뢰하는 경우, PKI는 한쪽에서 인증서를 사용하여 다른 쪽의 자격 증명을 설정할 수 있는 방법을 제공합니다. ACM 사용 설명서의 [개념](https://docs.aws.amazon.com/acm/latest/userguide/acm-concepts.html) 항목에 추가 배경 정보와 정의가 나와 있습니다.

- **AssumeRole**

  - https://docs.aws.amazon.com/ko_kr/STS/latest/APIReference/API_AssumeRole.html

- **X-Ray**
  
- 종단 간 추적
  - AWS 서비스 및 데이터베이스 통합
  - 다국어 지원
  
**프로덕션 분산 애플리케이션의 분석 및 디버깅**
  
> **AWS X-Ray는 개발자가 마이크로 서비스 아키텍처를 사용하여 구축 된 것과 같은 프로덕션 분산 애플리케이션을 분석하고 디버깅하는 데 도움이됩니다.** X-Ray를 사용하면 성능 문제 및 오류의 근본 원인을 식별하고 해결하기 위해 애플리케이션 및 기본 서비스의 성능을 이해할 수 있습니다. X-Ray는 요청이 애플리케이션을 통과 할 때 요청에 대한 종단 간보기를 제공하고 애플리케이션의 기본 구성 요소 맵을 표시합니다.
  >
  > X-Ray를 사용하여 AWS 계정에서 데이터를 수집 할 수 있습니다. X-Ray 에이전트는 실행중인 계정과 다른 계정에 데이터를 게시하는 역할을 맡을 수 있습니다. 이를 통해 애플리케이션의 다양한 구성 요소에서 중앙 계정으로 데이터를 게시 할 수 있습니다.
  
  - [https](https://aws.amazon.com/xray/) : [//aws.amazon.com/xray/](https://aws.amazon.com/xray/)
  
  AWS X-Ray는 개발자가 마이크로 서비스 아키텍처를 사용하여 구축 된 것과 같은 프로덕션 분산 애플리케이션을 분석하고 디버깅하는 데 도움이됩니다. X-Ray를 사용하면 성능 문제 및 오류의 근본 원인을 식별하고 해결하기 위해 애플리케이션 및 기본 서비스의 성능을 이해할 수 있습니다. X-Ray는 요청이 애플리케이션을 통과 할 때 요청에 대한 종단 간보기를 제공하고 애플리케이션의 기본 구성 요소 맵을 표시합니다.
  
  **X-Ray 서비스 사용** 
  
  AWS X-Ray는 개발자가 마이크로 서비스 아키텍처를 사용하여 구축 된 애플리케이션과 같은 프로덕션 분산 애플리케이션을 분석하고 디버그하는 데 도움이됩니다. X-Ray를 사용하면 애플리케이션 및 기본 서비스의 성능을 이해하여 성능 문제 및 오류의 근본 원인을 식별하고 해결할 수 있습니다. X-Ray는 요청이 애플리케이션을 통과 할 때 요청에 대한 종단 간보기를 제공하고 애플리케이션의 기본 구성 요소 맵을 표시합니다. X-Ray를 사용하여 간단한 3 계층 애플리케이션에서 수천 개의 서비스로 구성된 복잡한 마이크로 서비스 애플리케이션에 이르기까지 개발 및 프로덕션 애플리케이션을 모두 분석 할 수 있습니다.
  
  **X-Ray 샘플링 활성화**
  
  효율적인 추적을 보장하고 애플리케이션이 제공하는 요청의 대표적인 샘플을 제공하기 위해 X-Ray SDK는 샘플링 알고리즘을 적용하여 추적 할 요청을 결정합니다. 기본적으로 X-Ray SDK는 매초 첫 번째 요청과 추가 요청의 5 %를 기록합니다. X-Ray 샘플링은 AWS 콘솔에서 직접 활성화되므로 애플리케이션 코드를 변경할 필요가 없습니다.
  
  **IAM 역할 수정**
  
  쓰기 권한이있는 IAM 역할을 생성하고 애플리케이션을 실행하는 리소스에 할당합니다. AWS Identity and Access Management (IAM)를 사용하여 계정의 사용자 및 컴퓨팅 리소스에 X-Ray 권한을 부여 할 수 있습니다. 다른 문제 해결 옵션을 탐색하기 전에 권한이 올바르게 구성되었는지 확인하여 시작하는 첫 번째 장소 중 하나 여야합니다.

---

- **VPC 흐름 로그** 

  - VPC 흐름 로그는 VPC의 네트워크 인터페이스에서 송수신되는 IP 트래픽에 대한 정보를 캡처 할 수있는 기능입니다. 흐름 로그 데이터는 네트워크 추적을 분석하는 데 사용되며 네트워크 보안에 도움이됩니다. 흐름 로그 데이터는 Amazon CloudWatch Logs 또는 Amazon S3에 게시 할 수 있습니다. **VPC 흐름 로그를 사용하여 계정간에 데이터를 디버깅하고 추적 할 수 없습니다.**

- **CloudWatch Events**
  
- **S3 및 CloudWatch Logs 통합 활성화** 
  
  - AWS CodeBuild는 사용자를 대신하여 기능을 모니터링하고 Amazon CloudWatch를 통해 지표를보고합니다. 이러한 측정 항목에는 총 빌드 수, 실패한 빌드, 성공한 빌드 및 빌드 기간이 포함됩니다. 프로젝트 수준, AWS 계정 수준의 두 가지 수준에서 빌드를 모니터링 할 수 있습니다. 로그 그룹의 로그 데이터를 Amazon S3 버킷으로 내보내고이 데이터를 사용자 지정 처리 및 분석에 사용하거나 다른 시스템에로드 할 수 있습니다.
  
- Amazon CloudWatch Events는 Amazon Web Services (AWS) 리소스의 변경 사항을 설명하는 거의 실시간에 가까운 시스템 이벤트 스트림을 제공합니다. 이는 AWS 서비스에서 발생하는 변경 사항에 따라 알림을 트리거하는 데 도움이됩니다. CloudWatch 이벤트를 사용하여 계정간에 데이터를 디버깅하고 추적 할 수 없습니다.
  
- **CloudTrail** 
  
  - **CloudTrail을** 사용하면 AWS 인프라 전체에서 작업과 관련된 계정 활동을 기록하고, 지속적으로 모니터링하고, 유지할 수 있습니다. <u>AWS CloudTrail을 사용하여 "이 리소스를 수정하기 위해 API를 호출 한 사람은 누구입니까?"와 같은 질문에 답할 수 있습니다.</u> CloudTrail은 AWS 계정 활동의 이벤트 기록을 제공하여 AWS 계정의 거버넌스, 규정 준수, 운영 감사 및 위험 감사를 가능하게합니다. **CloudTrail을 사용하여 계정간에 데이터를 디버깅하고 추적 할 수 없습니다.**
  
  **AWS CloudTrail을 사용하여 S3에 로그 전송** -AWS CodeBuild는 CodeBuild에서 사용자, 역할 또는 AWS 서비스가 수행 한 작업 기록을 제공하는 서비스 인 AWS CloudTrail과 통합됩니다. CloudTrail은 CodeBuild 콘솔의 호출과 CodeBuild API에 대한 코드 호출을 포함하여 CodeBuild에 대한 모든 API 호출을 이벤트로 캡처합니다. 추적을 생성하면 CodeBuild에 대한 이벤트를 포함하여 CloudTrail 이벤트를 S3 버킷에 지속적으로 전달할 수 있습니다. 이것은 서비스 모니터링을위한 중요한 기능이지만 현재 시나리오에는 적합하지 않습니다.
  
  **CloudTrail**
  
  - 가시성 향상-CloudTrail은 AWS API 호출을 기록하여 사용자 활동에 대한 가시성을 향상시킵니다. 특정 사용자가 특정 기간 동안 어떤 작업을 수행했는지와 같은 질문에 답할 수 있습니다. **주어진 자원에 대해 주어진 기간 동안 어떤 사용자가 조치를 취했습니까? 특정 활동의 소스 IP 주소는 무엇입니까? 부적절한 권한으로 인해 실패한 활동은 무엇입니까?**
  - 견고하고 저렴한 로그 파일 스토리지-CloudTrail은 로그 파일 저장 및 전송에 Amazon S3를 사용하므로 로그 파일이 내구성 있고 저렴하게 저장됩니다. Amazon S3 수명주기 구성 규칙을 사용하여 스토리지 비용을 더욱 줄일 수 있습니다. 예를 들어, 추가 비용 절감을 위해 오래된 로그 파일을 자동으로 삭제하거나 Amazon Glacier에 보관하는 규칙을 정의 할 수 있습니다.
  - 간편한 관리-CloudTrail은 완전 관리 형 서비스입니다.
  
- **Amazon Inspector** 

  - Amazon Inspector는 AWS에 배포 된 애플리케이션의 보안 및 규정 준수를 개선하는 데 도움이되는 자동화 된 보안 평가 서비스입니다. Amazon Inspector 보안 평가는 Amazon EC2 인스턴스의 의도하지 않은 네트워크 액세스 가능성과 해당 EC2 인스턴스의 취약성을 확인하는 데 도움이됩니다. 이는 계정 수준에서 사용자 활동을 기록하지 않습니다.

- **CloudWatch 지표** 

  - CloudWatch는 데이터와 실행 가능한 통찰력을 제공하여 애플리케이션을 모니터링하고, 시스템 전반의 성능 변화에 대응하고, 리소스 사용률을 최적화하고, 운영 상태에 대한 통합보기를 얻습니다.
    Amazon CloudWatch를 사용하면 AWS에서 실행하는 AWS 클라우드 리소스와 애플리케이션을 모니터링 할 수 있습니다. 여러 AWS 제품 및 서비스에 대한 지표가 자동으로 제공됩니다. CloudWatch는 KMS API 호출의 소스를 확인하는 데 도움이되지 않습니다.

- **SSL / TLS**
  
- https://blog.naver.com/PostView.nhn?blogId=nine01223&logNo=221593556488&parentCategoryNo=&categoryNo=16&viewDate=&isShowPopularPosts=false&from=postView
  
- **Application Load Balancer**

  - https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html

- **AWS Serverless Application Model (AWS SAM)**

  - SAM은 다음 리소스 유형을 지원합니다.

    - AWS :: 서버리스 :: Api

    - AWS :: 서버리스 :: 애플리케이션

    - AWS :: 서버리스 :: 기능

    - AWS :: 서버리스 :: HttpApi

    - AWS :: 서버리스 :: LayerVersion

    - AWS :: 서버리스 :: SimpleTable

    - AWS :: 서버리스 :: StateMachine

      **AWS :: Serverless :: Function-** 이 리소스는 함수를 트리거하는 Lambda 함수, IAM 실행 역할 및 이벤트 소스 매핑을 생성합니다.

      **AWS :: Serverless :: Api** -HTTPS 엔드 포인트를 통해 호출 할 수있는 Amazon API Gateway 리소스 및 메서드 모음을 생성합니다. API를 구성 할 때 완전한 제어와 유연성을 원하는 고급 사용 사례에 유용합니다.

      **AWS :: Serverless :: SimpleTable-** 단일 속성 기본 키가있는 DynamoDB 테이블을 생성합니다. 기본 키를 통해서만 데이터에 액세스해야 할 때 유용합니다.
    
  - AWS 서버리스 애플리케이션 모델 (AWS SAM)은 AWS에서 서버리스 애플리케이션을 구축하는 데 사용할 수있는 오픈 소스 프레임 워크입니다.

    서버리스 애플리케이션은 Lambda 함수, 이벤트 소스 및 작업을 수행하기 위해 함께 작동하는 기타 리소스의 조합입니다. 서버리스 애플리케이션은 단순한 Lambda 함수가 아니라 API, 데이터베이스 및 이벤트 소스 매핑과 같은 추가 리소스를 포함 할 수 있습니다.

    SAM (Serverless Application Model) 템플릿에는 몇 가지 주요 섹션이 포함됩니다. **변환(Transform) 및 리소스는 유일한 필수 섹션입니다.**

- **UserPool**

  - UserPool은 모바일 앱 및 웹 인증에 사용되는 Cognito 서비스에 적용됩니다. 서버리스 애플리케이션 모델에는 UserPool이라는 리소스가 없습니다.

- **CNAME swap**

  - EB(Elastic Beanstalk)에서 나오는 개념
  - 말그대로 2개의 리소스? 코드?를 swap

- **AWS Elastic Beanstalk에 대한 구성 파일을 생성 할 때 따라야하는 명명 규칙은 무엇입니까?**

  - .ebextensions/<mysettings>.config
    - `.ebextensions`웹 애플리케이션의 소스 코드에 AWS Elastic Beanstalk 구성 파일 ( )을 추가 하여 환경을 구성하고 여기에 포함 된 AWS 리소스를 사용자 지정할 수 있습니다. 구성 파일은 .ebextensions라는 폴더에 배치하고 애플리케이션 소스 번들에 배포하는 .config 파일 확장자가있는 YAML 또는 JSON 형식 문서입니다.

- KMS(AWS **K**ey **M**anagement **S**ervice(KMS))

  > AWS KMS(Key Management Service)를 사용하면 손쉽게 암호화 키를 생성 및 관리하고 다양한 AWS 서비스와 애플리케이션에서의 사용을 제어할 수 있습니다. AWS KMS는 FIPS 140-2에 따라 검증되었거나 검증 과정에 있는 하드웨어 보안 모듈을 사용하여 키를 보호하는 안전하고 복원력 있는 서비스입니다. 또한, AWS KMS는 AWS CloudTrail과도 통합되어 모든 키 사용에 관한 로그를 제공함으로써 각종 규제 및 규정 준수 요구 사항을 충족할 수 있게 지원합니다.

  - https://aws.amazon.com/ko/kms/

- **AWS CloudHSM**

  **AWS 클라우드상의 관리형 하드웨어 보안 모듈(HSM).**

  - https://aws.amazon.com/ko/cloudhsm/

  > AWS CloudHSM은 AWS 클라우드에서 자체 암호화 키를 손쉽게 생성 및 사용할 수 있도록 지원하는 클라우드 기반 하드웨어 보안 모듈(HSM)입니다. CloudHSM에서는 FIPS 140-2 레벨 3 인증 HSM을 사용하여 자체 암호화 키를 관리할 수 있습니다. CloudHSM은 PKCS#11, Java Cryptography Extensions(JCE) 및 Microsoft CryptoNG(CNG) 라이브러리와 같은 업계 표준 API를 사용하여 애플리케이션과 통합할 수 있는 유연성을 제공합니다.
  >
  > CloudHSM은 표준을 준수하며 구성에 따라 모든 키를 대부분의 상용 HSM으로 내보낼 수 있습니다. 사용자를 위해 하드웨어 프로비저닝, 소프트웨어 패치, 고가용성, 백업 등 시간 소모적인 관리 작업을 자동화하는 완전관리형 서비스입니다. 또한, CloudHSM을 사용하면 선결제 비용 없이 온디맨드로 HSM 용량을 추가 및 제거하여 신속하게 확장/축소할 수 있습니다.

- **KMS**

  **KMS는 CMK를 저장하고 클라이언트로부터 데이터를 수신하여 암호화하고 다시 보냅니다.**

  고객 마스터 키 (CMK)는 마스터 키의 논리적 표현입니다. CMK에는 키 ID, 생성 날짜, 설명 및 키 상태와 같은 메타 데이터가 포함됩니다. CMK에는 데이터 암호화 및 해독에 사용되는 키 자료도 포함되어 있습니다. KMS, AWS CloudHSM 클러스터에서 CMK를 생성하거나 키 관리 인프라에서 가져올 수 있습니다.

  AWS KMS는 대칭 및 비대칭 CMK를 지원합니다. 대칭 CMK는 암호화 및 암호 해독에 사용되는 256 비트 키를 나타냅니다. 비대칭 CMK는 암호화 및 복호화 또는 서명과 확인 (둘다는 아님)에 사용되는 RSA 키 쌍 또는 서명 및 확인에 사용되는 ECC (타원 곡선) 키 쌍을 나타냅니다.

  AWS KMS는 고객 관리 형 CMK, AWS 관리 형 CMK 및 AWS 소유 CMK의 세 가지 유형의 CMK를 지원합니다.

  ~~KMS는 암호화 호출마다 클라이언트로부터 CMK를 수신하고이를 통해 데이터를 암호화합니다~~ .-자신의 CMK (고객 마스터 키)를 가져올 수 있지만 한 번만 수행하면 필요에 따라 암호화 / 복호화 할 수 있습니다.

  ~~KMS는 CMK를 클라이언트에 전송하여 암호화를 수행 한 다음 CMK를 삭제합니다.~~ KMS는 CMK를 클라이언트에 전송하지 않고 KMS 자체가 암호화 한 다음 데이터를 해독합니다.

  ~~KMS는 각 Encrypt 호출에 대해 새 CMK를 생성하고 데이터를 암호화합니다.~~ KMS는 매번 새 키를 생성하지 않지만 KMS가 키를 교체하도록 할 수 있습니다. 모범 사례는 암호화 키의 광범위한 재사용을 권장하지 않으므로 새 키를 생성하는 것이 좋습니다.

- **MFA**

  - **SMS 문자 메시지 기반 MFA**
    - IAM 사용자 설정에 사용자의 SMS 호환 모바일 디바이스의 전화 번호가 포함 된 MFA 유형입니다. <u>사용자가 로그인하면 AWS는 SMS 문자 메시지로 6 자리 숫자 코드를 사용자의 모바일 디바이스로 보냅니다.</u> 사용자는 로그인하는 동안 두 번째 웹 페이지에 해당 코드를 입력해야합니다. <u>SMS 기반 MFA는 IAM 사용자 만 사용할 수 있으며 AWS 계정 루트 사용자로는이 유형의 MFA를 사용할 수 없습니다.</u>
  - **하드웨어 MFA 디바이스**
    - <u>이 하드웨어 디바이스는 6 자리 숫자 코드를 생성합니다.</u> 사용자는 로그인하는 동안 두 번째 웹 페이지에 장치에서이 코드를 입력해야합니다. 사용자에게 할당 된 각 MFA 디바이스는 고유해야합니다. 사용자는 인증 할 다른 사용자의 장치에서 코드를 입력 할 수 없습니다. <u>루트 사용자 인증에 사용할 수 있습니다.</u>
  - **U2F 보안 키** 
    - <u>컴퓨터의 USB 포트에 연결하는 장치입니다.</u> U2F는 FIDO Alliance에서 호스팅하는 개방형 인증 표준입니다. U2F 보안 키를 활성화하면 수동으로 코드를 입력하는 대신 자격 증명을 입력 한 다음 장치를 탭하여 로그인합니다. <u>루트 사용자 인증에 사용할 수 있습니다.</u>
  - **가상 MFA 디바이스** 

    - <u>휴대폰 또는 기타 디바이스에서 실행되고 물리적 디바이스를 에뮬레이트하는 소프트웨어 앱입니다. 장치는 6 자리 숫자 코드를 생성합니다.</u> 사용자는 로그인하는 동안 두 번째 웹 페이지에 장치의 유효한 코드를 입력해야합니다. 사용자에게 할당 된 각 가상 MFA 디바이스는 고유해야합니다. 사용자는 다른 사용자의 가상 MFA 디바이스에서 코드를 입력하여 인증 할 수 없습니다. <u>루트 사용자 인증에 사용할 수 있습니다.</u>

---

#### API Gateway

**단계 변수**(Stage Variables)

단계 변수는 API의 배포 단계와 관련된 구성 속성으로 정의 할 수있는 이름-값 쌍입니다. 환경 변수처럼 작동하며 API 설정 및 매핑 템플릿에서 사용할 수 있습니다. API Gateway의 배포 단계를 사용하면 알파, 베타 및 프로덕션과 같은 각 API에 대한 여러 릴리스 단계를 관리 할 수 있습니다. 단계 변수를 사용하여 다양한 백엔드 엔드 포인트와 상호 작용하도록 API 배포 단계를 구성 할 수 있습니다.

예를 들어 API는 백엔드 웹 호스트 (예 : http://example.com)에 HTTP 프록시로 GET 요청을 전달할 수 있습니다. 이 경우 백엔드 웹 호스트는 개발자가 프로덕션 엔드 포인트를 호출 할 때 API Gateway가 example.com을 호출하도록 단계 변수에 구성됩니다. 베타 엔드 포인트를 호출하면 API Gateway는 베타 단계의 단계 변수에 구성된 값을 사용하고 다른 웹 호스트 (예 : beta.example.com)를 호출합니다.

#### Lambda

**모든 환경 변수의 총 크기는 4KB를 초과하지 않아야합니다. 변수 수에는 제한이 없습니다.**

**Lambda 별칭**

Lambda 별칭은 특정 Lambda 함수 버전에 대한 포인터와 같습니다. 사용자는 별칭 ARN을 사용하여 함수 버전에 액세스 할 수 있습니다.

Lambda 별칭을 사용하면 백엔드에서 원하는 버전을 가리키는 "변경 가능한"Lambda 버전을 생성 할 수 있습니다. 이를 통해 시간이 지나도 안정적으로 유지 될 수있는 "dev", "test", prod "Lambda 별칭을 가질 수 있습니다.


- **API Gateway 사용량 계획 사용**

  - Amazon API Gateway는 규모에 관계없이 REST, HTTP 및 WebSocket API를 생성, 게시, 유지 관리, 모니터링 및 보호하기위한 AWS 서비스입니다. API 개발자는 AWS 또는 기타 웹 서비스와 AWS 클라우드에 저장된 데이터에 액세스하는 API를 생성 할 수 있습니다.

    사용량 계획은 배포 된 하나 이상의 API 단계 및 메서드에 액세스 할 수있는 사용자와 액세스 할 수있는 양과 속도를 지정합니다. 플랜은 API 키를 사용하여 API 클라이언트를 식별하고 각 키에 대한 관련 API 단계에 대한 액세스를 측정합니다.

    고객이 비즈니스 요구 사항 및 예산 제약을 충족하는 합의 된 요청 비율 및 할당량으로 선택한 API에 액세스 할 수 있도록 사용 계획 및 API 키를 구성 할 수 있습니다.

- **CloudFront**

  - Amazon CloudFront는 개발자 친화적 인 환경에서 짧은 지연 시간, 빠른 전송 속도로 전 세계 고객에게 데이터, 비디오, 애플리케이션 및 API를 안전하게 제공하는 **고속 콘텐츠 전송 네트워크 (CDN) 서비스**입니다. CloudFront 사용량 계획과 같은 것은 없습니다. CloudFront를 사용하여 애플리케이션에 대한 퍼블릭 API를 설정할 수 없습니다.

  - 정적 콘텐츠를 S3에 저장하면 많은 이점이 있습니다. 그러나 비용을 효과적으로 관리하면서 애플리케이션의 성능과 보안을 최적화하기 위해 AWS는 콘텐츠를 제공하고 보호하기 위해 S3 버킷과 함께 작동하도록 Amazon CloudFront를 설정하는 것이 좋습니다. CloudFront는 정적 및 동적 웹 콘텐츠, 비디오 스트림 및 API를 전 세계에 안전하게 대규모로 제공하는 콘텐츠 전송 네트워크 (CDN) 서비스입니다. 설계 상 CloudFront에서 데이터를 제공하는 것은 S3에서 사용자에게 직접 제공하는 것보다 비용 효율적일 수 있습니다.

    콘텐츠를 엣지 로케이션에 캐싱함으로써 CloudFront는 S3 버킷의 부하를 줄이고 사용자가 콘텐츠를 요청할 때 더 빠른 응답을 보장합니다. 또한 CloudFront를 사용하여 콘텐츠를 위해 데이터를 전송하는 것은 종종 S3에서 직접 파일을 제공하는 것보다 비용 효율적이며 S3에서 CloudFront 로의 데이터 전송 요금이 없습니다.

    CloudFront의 보안 기능은 OAI (Origin Access Identity)로, S3 버킷 및 해당 콘텐츠에 대한 액세스를 CloudFront 및 수행하는 작업으로 만 제한합니다.


#### CodeDeploy


- **CodeDeploy**

  - AWS CodeDeploy는 Amazon EC2, AWS Fargate, AWS Lambda 및 온 프레미스 서버와 같은 다양한 컴퓨팅 서비스에 대한 소프트웨어 배포를 자동화하는 완전 관리 형 배포 서비스입니다. AWS CodeDeploy를 사용하면 새로운 기능을보다 쉽게 신속하게 출시하고 애플리케이션 배포 중 다운 타임을 방지하고 애플리케이션 업데이트의 복잡성을 처리 할 수 있습니다. 인스턴스에 애플리케이션을 배포 할 수 있지만 인스턴스를 프로비저닝 할 수는 없습니다.
  - **ValidateService** : ValidateService는 마지막 배포 수명주기 이벤트입니다. 배포가 성공적으로 완료되었는지 확인하는 데 사용됩니다.
  - **AfterInstall-** 애플리케이션 구성 또는 파일 권한 변경과 같은 작업에이 배포 수명주기 이벤트를 사용할 수 있습니다.
  - **ApplicationStart-** 일반적으로이 배포 수명주기 이벤트를 사용하여 ApplicationStop 중에 중지 된 서비스를 다시 시작합니다.
  - **AllowTraffic-** 이 배포 수명주기 이벤트 동안 인터넷 트래픽은 배포 후 인스턴스에 액세스 할 수 있습니다. 이 이벤트는 AWS CodeDeploy 에이전트 용으로 예약되어 있으며 스크립트를 실행하는 데 사용할 수 없습니다.

  **블루 / 그린 배포 선택** -블루 / 그린 배포는 새 애플리케이션 버전의 변경으로 인한 중단을 최소화하면서 애플리케이션을 업데이트하는 데 사용됩니다. CodeDeploy는 프로덕션 트래픽을 다시 라우팅하기 전에 이전 버전과 함께 새 애플리케이션 버전을 프로비저닝합니다. 배포 동작은 사용하는 컴퓨팅 플랫폼에 따라 다릅니다.

  1. AWS Lambda : 트래픽이 한 버전의 Lambda 함수에서 동일한 Lambda 함수의 새 버전으로 이동됩니다.
  2. Amazon ECS : 트래픽이 Amazon ECS 서비스의 작업 세트에서 동일한 Amazon ECS 서비스의 업데이트 된 대체 작업 세트로 이동됩니다.
  3. EC2 / 온 프레미스 : 트래픽이 원래 환경의 한 인스턴스 세트에서 대체 인스턴스 세트로 이동합니다.

  **현재 위치 배포 선택** 

  - 이 배포 유형에서는 배포 그룹의 각 인스턴스에있는 애플리케이션이 중지되고 최신 애플리케이션 개정이 설치되며 새 버전의 애플리케이션이 시작되고 유효성이 검사됩니다. 로드 밸런서를 사용하여 각 인스턴스가 배포 중에 등록 취소 된 다음 배포가 완료된 후 서비스로 복원되도록 할 수 있습니다.

- **서버리스 애플리케이션 모델** 

  - AWS 서버리스 애플리케이션 모델 (AWS SAM)은 서버리스 애플리케이션을 구축하기위한 오픈 소스 프레임 워크입니다. 함수, API, 데이터베이스 및 이벤트 소스 매핑을 표현하는 약식 구문을 제공합니다. 자원 당 몇 줄로 원하는 애플리케이션을 정의하고 YAML을 사용하여 모델링합니다. 웹 애플리케이션을 EC2 인스턴스에 배포해야하므로이 옵션은 제외됩니다.

  

- **신뢰 정책**

  - 신뢰 정책은 역할을 맡을 수있는 주요 엔티티 (계정, 사용자, 역할 및 연합 사용자)를 정의합니다. IAM 역할은 리소스 기반 정책을 지원하는 자격 증명이자 리소스입니다. 따라서 IAM 역할에 신뢰 정책과 자격 증명 기반 정책을 모두 연결해야합니다. IAM 서비스는 IAM 역할에 연결된 역할 신뢰 정책이라는 한 가지 유형의 리소스 기반 정책 만 지원합니다.

- **AWS Organizations 서비스 제어 정책 (SCP)**

  - AWS 조직의 모든 기능을 활성화하면 서비스 제어 정책 (SCP)을 일부 또는 모든 계정에 적용 할 수 있습니다. SCP는 조직 또는 조직 구성 단위 (OU)에 대한 최대 권한을 지정하는 JSON 정책입니다. SCP는 각 AWS 계정 루트 사용자를 포함하여 구성원 계정의 엔터티에 대한 권한을 제한합니다. 이러한 정책의 명시 적 거부는 허용보다 우선합니다.

- **액세스 제어 목록 (ACL)** 

  - 액세스 제어 목록 (ACL)은 리소스에 액세스 할 수있는 **다른 계정의 보안 주체를 제어** 할 수있는 서비스 정책입니다. ACL은 동일한 계정 내에서 주체에 대한 액세스를 제어하는 데 사용할 수 없습니다. Amazon S3, AWS WAF 및 Amazon VPC는 ACL을 지원하는 서비스의 예입니다.

- **권한 경계** 

  - AWS는 IAM 엔터티 (사용자 또는 역할)에 대한 권한 경계를 지원합니다. 권한 경계는 관리 형 정책을 사용하여 자격 증명 기반 정책이 IAM 엔터티에 부여 할 수있는 최대 권한을 설정하기위한 고급 기능입니다. 엔터티의 권한 경계를 사용하면 ID 기반 정책과 권한 경계 모두에서 허용하는 작업 만 수행 할 수 있습니다.

- **Lambda Authorizer**

  - Amazon API Gateway Lambda authorizer (이전의 사용자 지정 authorizer)는 API에 대한 액세스를 제어하기 위해 제공하는 Lambda 함수입니다. Lambda authorizer는 OAuth 또는 SAML과 같은 Bearer 토큰 인증 전략을 사용합니다. API Gateway Lambda authorizer를 생성하기 전에 먼저 권한을 부여하고 필요한 경우 호출자를 인증하는 로직을 구현하는 AWS Lambda 함수를 생성해야합니다.

- **sigv4를 사용한 IAM 권한**

  - 서명 버전 4는 HTTP에서 전송 한 AWS 요청에 인증 정보를 추가하는 프로세스입니다. 여전히 권한을 제공해야하지만 요구 사항에는 Lambda Authorizer가 작동하는 타사 인증이 필요합니다.

- **Cognito 사용자 풀**

  - Cognito 사용자 풀은 Amazon Cognito의 사용자 디렉터리입니다. 사용자 풀을 사용하면 사용자가 Amazon Cognito를 통해 웹 또는 모바일 앱에 로그인하거나 타사 자격 증명 공급자 (IdP)를 통해 페더레이션 할 수 있습니다. 사용자가 직접 로그인하든 타사를 통해 로그인하든 사용자 풀의 모든 구성원은 SDK를 통해 액세스 할 수있는 디렉터리 프로필을 갖습니다. 이는 AWS에서 관리하므로 요구 사항을 충족하지 않습니다.

    "API 게이트웨이 사용자 풀"-이것은 산만하게 추가 된 구성 옵션입니다.

- **Cognito 자격 증명 풀**

  - 자격 증명 풀을 사용하여 사용자에게 다른 AWS 서비스에 대한 액세스 권한을 부여 할 수 있습니다. 자격 증명 풀을 통해 사용자는 Amazon S3 및 DynamoDB와 같은 AWS 서비스에 액세스하기위한 임시 AWS 자격 증명을 얻을 수 있습니다. 자격 증명 풀은 익명 게스트 사용자와 자격 증명 풀에 대한 사용자를 인증하는 데 사용할 수있는 특정 자격 증명 공급자를 지원합니다.

- **Amazon Elastic Container Registry (ECR)**

  - Amazon Elastic Container Registry (ECR)는 개발자가 Docker 컨테이너 이미지를 쉽게 저장, 관리 및 배포 할 수있게 해주는 완전 관리 형 Docker 컨테이너 레지스트리입니다. Amazon ECR은 Amazon Elastic Container Service (ECS)와 통합되어 개발에서 프로덕션 워크 플로까지 간소화합니다.

- **Amazon Elastic Container Service(ECS)** 

  - Amazon Elastic Container Service (Amazon ECS)는 클러스터에서 Docker 컨테이너를 쉽게 실행, 중지 및 관리 할 수있는 확장 성이 뛰어나고 빠른 컨테이너 관리 서비스입니다. Fargate 시작 유형을 사용하여 서비스 또는 작업을 시작하여 Amazon ECS에서 관리하는 서버리스 인프라에서 클러스터를 호스팅 할 수 있습니다. 인프라에 대한 더 많은 제어를 위해 EC2 시작 유형을 사용하여 관리하는 Amazon Elastic Compute Cloud (Amazon EC2) 인스턴스 클러스터에서 작업을 호스팅 할 수 있습니다.

    ECS를 사용하여 Docker 이미지를 저장하고 배포 할 수 없습니다.

#### EBS


- **EBS**(Amazon Elastic Block Store) 

  - Amazon Elastic Block Store (EBS)는 모든 규모의 처리량과 트랜잭션 집약적 인 워크로드 모두를 위해 Amazon Elastic Compute Cloud (EC2)와 함께 사용하도록 설계된 사용하기 쉬운 고성능 블록 스토리지 서비스입니다. EBS는 Docker 이미지를 저장하고 배포하는 데 사용할 수 없습니다.
  - **15000 IOPS의 200GiB 크기 볼륨** -잘못된 구성입니다. 프로비저닝 된 IOPS 대 요청 된 볼륨 크기 (GiB)의 **최대 비율은 50 : 1**입니다. 따라서 200GiB 볼륨 크기의 경우 가능한 최대 IOPS는 200 * 50 = 10000 IOPS입니다.

  **Amazon EC2 시작 중에 생성 된 EBS 볼륨** 에는 'CreateVolume'에 대한 AWS CloudTrail 이벤트 로그를 사용할 수 없습니다. Amazon Elastic Compute Cloud (Amazon EC2) 시작 중에 생성 된 EBS 볼륨에는 'CreateVolume'에 대한 AWS CloudTrail 이벤트 로그를 사용할 수 없습니다.

  

- **CodeBuild** 

  - AWS CodeBuild는 소스 코드를 컴파일하고 테스트를 실행하며 배포 할 준비가 된 소프트웨어 패키지를 생성하는 완전 관리 형 지속적 통합 서비스입니다. 응용 프로그램을 배포하는 데 사용할 수 없습니다.

- **Elastic Beanstalk** 

  - AWS Elastic Beanstalk는 후크를 제공하지만 CodeDeploy만큼 많은 제어를 제공하지는 않습니다. AWS Elastic Beanstalk는 애플리케이션 버전을 업데이트 할 때 인플레 이스 업데이트를 수행하기 때문에 짧은 기간 동안 사용자가 애플리케이션을 사용할 수 없게 될 수 있습니다. 블루 / 그린 배포를 수행하여 이러한 다운 타임을 피할 수 있습니다. 여기서 새 버전을 별도의 환경에 배포 한 다음 두 환경의 CNAME을 교체하여 트래픽을 새 버전으로 즉시 리디렉션 할 수 있습니다.

- **CodePipeline** 

  - CodePipeline은 코드가 변경 될 때마다 릴리스 프로세스의 빌드, 테스트 및 배포 단계를 자동화합니다. CodePipeline 자체로는 애플리케이션을 배포 할 수 없습니다.

  - **전체 흐름에 대해 하나의 CodePipeline을 생성하고 수동 승인 단계** 추가-누군가가 작업을 수동으로 승인하거나 거부 할 수 있도록 파이프 라인을 중지하려는 지점에서 CodePipeline 파이프 라인의 단계에 승인 작업을 추가 할 수 있습니다. 승인 작업은 소스 단계에 추가 할 수 없습니다. 소스 단계에는 소스 작업 만 포함될 수 있습니다.

    **각 환경에 대해 여러 CodePipelines를 생성하고 AWS Lambda를 사용하여 연결-Lambda** 함수를 생성하고 파이프 라인에서 작업으로 추가 할 수 있지만 승인 단계는 워크 플로 프로세스로 제한되며 다른 AWS 서비스로 아웃소싱 할 수 없습니다.

    **각 환경에 대해 긴밀하게 통합 된 AWS CodePipelines 생성** -AWS CodePipeline 및 AWS CodeCommit과 함께 AWS CloudFormation 템플릿을 사용하여 애플리케이션에 대한 변경 사항이 승인되면 프로덕션 환경에 배포하는 테스트 환경을 생성하여 지속적 배포를 자동화 할 수 있습니다. 워크 플로우. 이것은 가능한 대답이지만 클라이언트가 필요로하는 것을 달성하는 최적화 된 방법은 아닙니다.

    **Amazon Virtual Private Cloud와 함께 CodePipeline 사용-AWS** CodePipeline은 AWS PrivateLink에서 제공하는 Amazon Virtual Private Cloud (Amazon VPC) 엔드 포인트를 지원합니다. 즉, VPC의 프라이빗 엔드 포인트를 통해 CodePipeline에 직접 연결하여 모든 트래픽을 VPC 및 AWS 네트워크 내부에 유지할 수 있습니다. 이것은 강력한 보안 기능이지만 현재 사용 사례에는 가치가 없습니다.

    

- **ALB 액세스 로그** -Elastic Load Balancing은로드 밸런서로 전송 된 요청에 대한 자세한 정보를 캡처하는 액세스 로그를 제공합니다. 각 로그에는 요청이 수신 된 시간, 클라이언트의 IP 주소, 대기 시간, 요청 경로 및 서버 응답과 같은 정보가 포함됩니다. 이러한 액세스 로그를 사용하여 트래픽 패턴을 분석하고 문제를 해결할 수 있습니다. 액세스 로깅은 기본적으로 비활성화되는 Elastic Load Balancing의 선택적 기능입니다.

#### ALB

ALB 뒤에서 실행되는 사이버 포렌식 애플리케이션은 클라이언트 IP에 대한 패턴을 분석하려고합니다. 이 요구 사항에 사용할 수있는 헤더는 무엇입니까? 

- **X-Forwarded-For** 

  - X-Forwarded-For 요청 헤더는 HTTP 또는 HTTPS로드 밸런서를 사용할 때 클라이언트의 IP 주소를 식별하는 데 도움이됩니다. 로드 밸런서는 클라이언트와 서버 간의 트래픽을 가로 채기 때문에 서버 액세스 로그에는로드 밸런서의 IP 주소 만 포함됩니다. 클라이언트의 IP 주소를 보려면 X-Forwarded-For 요청 헤더를 사용하십시오.

  잘못된 옵션 :

  - **X-Forwarded-Proto** -X-Forwarded-Proto 요청 헤더는 클라이언트가로드 밸런서에 연결하는 데 사용한 프로토콜 (HTTP 또는 HTTPS)을 식별하는 데 도움이됩니다. 서버 액세스 로그에는 서버와로드 밸런서간에 사용되는 프로토콜 만 포함됩니다. 여기에는 클라이언트와로드 밸런서간에 사용되는 프로토콜에 대한 정보가 없습니다. 클라이언트와로드 밸런서간에 사용되는 프로토콜을 확인하려면 X-Forwarded-Proto 요청 헤더를 사용합니다.

  - **X-Forwarded-Port** -X-Forwarded-Port 요청 헤더는 클라이언트가로드 밸런서에 연결하는 데 사용한 대상 포트를 식별하는 데 도움이됩니다.

  - **X-Forwarded-IP-** 이것은 구성 옵션이며 선택 항목으로 추가되었습니다.

#### EC2

영역 **예약 인스턴스** -영역 예약 인스턴스는 지정된 가용 영역에서 용량 예약을 제공합니다. 용량 예약을 사용하면 특정 가용 영역에서 Amazon EC2 인스턴스의 용량을 원하는 기간 동안 예약 할 수 있습니다. 이를 통해 Savings Plans 또는 리전 예약 인스턴스에서 제공하는 청구 할인과는 별도로 용량 예약을 생성하고 관리 할 수 있습니다.


- **전용 인스턴스** 

  - 전용 인스턴스는 단일 고객 전용 하드웨어의 가상 사설 클라우드 (VPC)에서 실행되는 Amazon EC2 인스턴스입니다. 다른 AWS 계정에 속하는 전용 인스턴스는 해당 계정이 단일 지불 자 계정에 연결되어 있더라도 하드웨어 수준에서 물리적으로 격리됩니다. 그러나 전용 인스턴스는 전용 인스턴스가 아닌 동일한 AWS 계정의 다른 인스턴스와 하드웨어를 공유 할 수 있습니다.

  - 전용 호스트는 사용자 전용으로 사용되는 물리적 서버이기도합니다. 전용 호스트를 사용하면 인스턴스가 서버에 배치되는 방식을 파악하고 제어 할 수 있습니다.

- **전용 호스트** 

  - Amazon EC2 전용 호스트는 사용 전용 EC2 인스턴스 용량이있는 물리적 서버입니다. 전용 호스트를 사용하면 EC2 인스턴스에서 기존 소프트웨어 라이선스를 사용할 수 있습니다. 전용 호스트를 사용하면 인스턴스가 서버에 배치되는 방식을 파악하고 제어 할 수 있습니다. 이 옵션은 전용 인스턴스보다 비용이 많이 들기 때문에 현재 요구 사항에 적합한 선택이 아닙니다.

- **EC2 스팟 인스턴스** 

  - 스팟 인스턴스는 온 디맨드 가격보다 저렴한 가격으로 제공되는 미사용 EC2 인스턴스입니다. 스팟 인스턴스는 용량을 사용할 수 있고 요청에 대한 시간당 최고 가격이 스팟 가격을 초과 할 때마다 실행됩니다. 사용되지 않은 용량이있는 모든 인스턴스가 할당됩니다. 비용 효율적이지만 클라이언트의 단일 테넌트 하드웨어 요구 사항을 충족하지 못하므로 올바른 옵션이 아닙니다.

    Amazon EC2가 스팟 인스턴스를 중단 할 때 다음 중 하나를 수행하도록 지정할 수 있습니다.

    - 스팟 인스턴스 중지

    - 스팟 인스턴스를 최대 절전 모드로 전환

    - 스팟 인스턴스 종료

    - 기본값은 중단 될 때 스팟 인스턴스를 종료하는 것입니다.

    - **스팟 인스턴스 재부팅** -이것은 잘못된 옵션입니다.

- **Auto Scaling 그룹**

  - Auto Scaling 그룹은 여러 리전에 걸쳐있을 수 없습니다.

  - Auto Scaling 그룹은 동일한 리전 내의 하나 이상의 가용 영역에 EC2 인스턴스를 포함 할 수 있습니다.
  - **Auto Scaling 그룹은 동일한 리전 내의 하나 이상의 가용 영역에 EC2 인스턴스를 포함 할 수 있습니다** Auto Scaling 그룹은 리전의 가용 영역에 걸쳐있을 수 있습니다.
  - **Amazon EC2 Auto Scaling은 Auto Scaling 그룹에 대해 활성화 된 가용 영역간에 인스턴스를 균등하게 배포하려고 시도합니다** 하나의 가용 영역이 비정상이거나 사용할 수 없게되면 Auto Scaling은 영향을받지 않는 가용 영역에서 새 인스턴스를 시작합니다. 비정상 가용 영역이 정상 상태로 돌아 가면 Auto Scaling은 지정된 모든 가용 영역에 애플리케이션 인스턴스를 균등하게 자동으로 재배포합니다.
  - **VPC의 Auto Scaling 그룹의 경우 EC2 인스턴스가 서브넷에서 시작됩니다. **VPC의 Auto Scaling 그룹의 경우 EC2 인스턴스가 서브넷에서 시작됩니다. 고객은 Auto Scaling 그룹을 생성하거나 업데이트 할 때 EC2 인스턴스의 서브넷을 선택할 수 있습니다.

- **AWS Kinesis 데이터 스트림**

  - Amazon Kinesis Data Streams (KDS)는 확장 성이 뛰어나고 내구성이 뛰어난 실시간 데이터 스트리밍 서비스입니다. KDS는 웹 사이트 클릭 스트림, 데이터베이스 이벤트 스트림, 금융 거래, 소셜 미디어 피드, IT 로그 및 위치 추적 이벤트와 같은 수십만 소스에서 초당 기가 바이트의 데이터를 지속적으로 캡처 할 수 있습니다. 수집 된 데이터는 밀리 초 단위로 제공되어 실시간 대시 보드, 실시간 이상 탐지, 동적 가격 책정 등과 같은 실시간 분석 사용 사례를 지원합니다.

  - Amazon Kinesis Data Streams를 사용하면 스트리밍 빅 데이터를 실시간으로 처리 할 수 있습니다. 여러 Amazon Kinesis 애플리케이션에 동일한 순서로 레코드를 읽거나 재생할 수있는 기능뿐 아니라 레코드 순서를 제공합니다. Amazon Kinesis Client Library (KCL)는 주어진 파티션 키에 대한 모든 레코드를 동일한 레코드 프로세서로 전송하므로 동일한 Amazon Kinesis 데이터 스트림에서 읽는 여러 애플리케이션을 쉽게 구축 할 수 있습니다 (예 : 계산, 집계 및 필터링 수행). . Amazon Kinesis Data Streams는 여러 애플리케이션이 동일한 스트림을 동시에 사용할 수있는 기능이 필요한 경우에 권장됩니다. 예를 들어 실시간 대시 보드를 업데이트하는 애플리케이션과 Amazon Redshift에 데이터를 보관하는 다른 애플리케이션이 있습니다.

  - ProvisionedThroughputExceeded 예외로 인해 애플리케이션이 데이터 처리를 중지했습니다.

    다음 중이 문제를 해결하는 데 도움이되는 조치는 무엇입니까? 

    - **지수 백오프(backoff)로 재 시도하도록 데이터 생산자 구성**
    - **충분한 용량을 제공하기 위해 데이터 스트림 내 샤드 수를 늘립니다.**

    Amazon Kinesis Data Streams를 사용하면 특수한 요구에 맞게 스트리밍 데이터를 처리하거나 분석하는 사용자 지정 애플리케이션을 구축 할 수 있습니다. 클릭 스트림, 애플리케이션 로그 및 소셜 미디어와 같은 다양한 유형의 데이터를 수십만 소스의 Amazon Kinesis 데이터 스트림에 지속적으로 추가 할 수 있습니다.
    Amazon Kinesis 데이터 스트림의 용량 제한은 데이터 스트림 내의 샤드 수로 정의됩니다. 제한은 데이터 처리량 또는 PUT 레코드 수로 초과 될 수 있습니다. 용량 제한을 초과하는 동안 데이터 넣기 호출은 ProvisionedThroughputExceeded 예외와 함께 거부됩니다.

    이것이 데이터 스트림의 입력 데이터 속도의 일시적인 상승으로 인한 경우 데이터 생산자의 재시도 (지수 백 오프 포함)는 결국 요청 완료로 이어집니다.이것이 데이터 스트림의 입력 데이터 속도의 일시적인 상승으로 인한 경우 데이터 생산자의 재시도 (지수 백 오프 포함)는 결국 요청 완료로 이어집니다.

    이것이 데이터 스트림의 입력 데이터 속도의 지속적인 상승으로 인한 경우 데이터 스트림 내의 샤드 수를 늘려 데이터 넣기 호출이 지속적으로 성공할 수있는 충분한 용량을 제공해야합니다.

- **AWS Kinesis Data Firehose**  

  - Amazon Kinesis Data Firehose는 스트리밍 데이터를 데이터 스토어 및 분석 도구에로드하는 가장 쉬운 방법입니다. 스트리밍 데이터를 캡처, 변환 및 Amazon S3, Amazon Redshift, Amazon Elasticsearch Service 및 Splunk로 로드 할 수 있으므로 현재 이미 사용중인 기존 비즈니스 인텔리전스 도구 및 대시 보드를 통해 거의 실시간 분석이 가능합니다. 데이터 처리량에 맞게 자동으로 확장되고 지속적인 관리가 필요하지 않은 완전 관리 형 서비스입니다. 또한 데이터를로드하기 전에 일괄 처리, 압축 및 암호화하여 대상에서 사용되는 스토리지 양을 최소화하고 보안을 강화할 수 있습니다. Kinesis Data Firehose는 스트리밍 데이터를 데이터 스토어로로드하는 데 사용되므로이 옵션은 올바르지 않습니다.

    Kinesis Data Firehose를 사용하면 애플리케이션을 작성하거나 리소스를 관리 할 필요가 없습니다. Kinesis Data Firehose로 데이터를 전송하도록 데이터 생산자를 구성하면 지정한 대상으로 데이터가 자동으로 전송됩니다.

- **Kinesis Data Firehose**는 스트리밍 데이터를 데이터 스토어 (Amazon S3, Amazon Redshift, Amazon Elasticsearch Service 및 Splunk)로 로드하는 데 사용되는 반면 **Kinesis Data Streams**는 스트리밍 데이터의 실시간 처리를 지원합니다. 여러 다운 스트림 Amazon Kinesis 애플리케이션에 동일한 순서로 레코드를 읽거나 재생할 수있는 기능뿐 아니라 레코드 순서를 제공합니다.

- **AWS Kinesis Data Analytics** 

  - Amazon Kinesis Data Analytics는 스트리밍 데이터를 실시간으로 분석하는 가장 쉬운 방법입니다. 모든 규모의 데이터를 구성, 변환, 집계 및 분석하기위한 공통 처리 기능을위한 기본 제공 템플릿 및 연산자를 사용하여 SQL 쿼리 및 정교한 Java 애플리케이션을 빠르게 빌드 할 수 있습니다. Kinesis Data Analytics를 사용하면 스트리밍 데이터 원본 설정, 쿼리 또는 스트리밍 애플리케이션 작성, 처리 된 데이터 대상 설정의 세 가지 간단한 단계로 쿼리와 정교한 스트리밍 애플리케이션을 쉽고 빠르게 구축 할 수 있습니다. Kinesis Data Analytics는 SQL 쿼리 및 정교한 Java 애플리케이션을 빌드하는 데 사용되므로이 옵션은 올바르지 않습니다.

- **Amazon SQS** 

  - **SQS 확장 클라이언트 사용** 
    - 대규모 Amazon Simple Queue Service (Amazon SQS) 메시지를 관리하기 위해 Amazon Simple Storage Service (Amazon S3) 및 Amazon SQS Extended Client Library for Java를 사용할 수 있습니다. 이는 최대 2GB의 메시지를 저장하고 소비하는 데 특히 유용합니다. 애플리케이션에서 반복적으로 대기열을 생성하고 비활성 상태로 두거나 대기열에 많은 양의 데이터를 저장해야하는 경우가 아니면 Amazon S3를 사용하여 데이터를 저장하는 것이 좋습니다.
  
  - **Amazon SQS는 확장 성이 뛰어나며 예상되는 대용량을 처리하기 위해 개입이 필요하지 않습니다.**
  
  - Amazon Simple Queue Service (SQS)는 마이크로 서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장 할 수있는 완전 관리 형 메시지 대기열 서비스입니다. SQS는 두 가지 유형의 메시지 대기열을 제공합니다. 표준 대기열은 최대 처리량, 최선형 주문 및 최소 1 회 전달을 제공합니다. SQS FIFO 대기열은 메시지가 전송 된 정확한 순서대로 정확히 한 번 처리되도록 설계되었습니다. SQS의 경우 여러 소비자가 동시에 동일한 메시지를 사용할 수 없으므로이 옵션은 올바르지 않습니다.
  
  - **SQS 긴 폴링을 사용하여 Amazon SQS 대기열에서 메시지 검색**
  
    Amazon Simple Queue Service (SQS)는 마이크로 서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장 할 수있는 완전 관리 형 메시지 대기열 서비스입니다.
  
    Amazon SQS는 대기열에서 메시지를 수신하기 위해 짧은 폴링과 긴 폴링을 제공합니다. 기본적으로 큐는 짧은 폴링을 사용합니다. 짧은 폴링을 사용하면 Amazon SQS는 쿼리에서 메시지를 찾지 못한 경우에도 즉시 응답을 보냅니다. 긴 폴링을 사용하면 Amazon SQS가 사용 가능한 메시지를 하나 이상 수집 한 후 요청에 지정된 최대 메시지 수까지 응답을 보냅니다. Amazon SQS는 폴링 대기 시간이 만료 된 경우에만 빈 응답을 보냅니다.
  
    긴 폴링을 사용하면 메시지를 사용할 수있게되는 즉시 Amazon SQS 대기열에서 메시지를 검색하는 것이 저렴합니다. 긴 폴링은 빈 응답 (ReceiveMessage 요청에 사용할 수있는 메시지가없는 경우) 및 거짓 빈 응답 (메시지를 사용할 수 있지만 응답에 포함되지 않은 경우)을 제거하여 Amazon SQS 사용 비용을 줄이는 데 도움이됩니다. ReceiveMessage API 조치의 대기 시간이 0보다 크면 긴 폴링이 적용됩니다. 최대 긴 폴링 대기 시간은 20 초입니다.

#### IAM

- **IAM 정책 변수**

  - 각 사용자에 대한 개별 정책을 만드는 대신 정책 변수를 사용하고 여러 사용자에게 적용되는 단일 정책 (그룹 정책)을 만들 수 있습니다. 정책 변수는 자리 표시 자 역할을합니다. AWS에 요청하면 자리 표시자는 정책이 평가 될 때 요청의 값으로 대체됩니다.

    예를 들어, 다음 정책은 그룹의 각 사용자에게 Amazon S3의 사용자 별 객체 (자신의 "홈 디렉터리")에 대한 완전한 프로그래밍 액세스 권한을 부여합니다.

- **IAM 정책 주체** 
  
  - **정책** 의 Principal 요소를 사용하여 리소스에 대한 액세스를 허용하거나 거부하는 주체를 지정할 수 있습니다 (IAM에서 주체는 AWS에서 작업 또는 작업을 요청할 수있는 사람 또는 애플리케이션입니다. 보안 주체는 AWS에 요청하기 위해 AWS 계정 루트 사용자 또는 IAM 엔터티로 인증됩니다. IAM 자격 증명 기반 정책에서는 Principal 요소를 사용할 수 없습니다. IAM 역할에 대한 신뢰 정책 및 리소스 기반 정책에서 사용할 수 있습니다.
  
- **IAM 정책 조건**
  
  - **Condition** 요소 (또는 Condition 블록)를 사용하면 정책이 적용될 때 조건을 지정할 수 있습니다 (예 :) `"Condition" : { "StringEquals" : { "aws:username" : "johndoe" }}`. 
  
- **IAM 정책 리소스**
  
  - **Resource** 요소는 문이 다루는 객체를 지정합니다. ARN을 사용하여 리소스를 지정합니다. 
  
- **IAM 역할 및 리소스 기반 정책은 단일 파티션 내에서만 계정 간의 액세스 권한을 위임합니다.** 예를 들어 표준 `aws`파티션 에 미국 서부 (캘리포니아 북부)에 계정이 있다고 가정 합니다. `aws-cn`파티션 에 중국 (베이징)의 계정도 있습니다 . 중국 (베이징)의 계정에서 Amazon S3 리소스 기반 정책을 사용하여 표준 AWS 계정의 사용자에게 액세스를 허용 할 수 없습니다.

- **S3 버킷 객체에 대한 프로그래밍 방식 전용 액세스를 위해 리소스 기반 정책 및 AWS Identity and Access Management (IAM) 정책** 사용-버킷 정책을 사용하여 교차 계정 제어를 관리하고 S3 객체의 권한을 감사합니다. 버킷 수준에서 버킷 정책을 적용하면 액세스 할 수있는 사람 (Principal 요소), 액세스 할 수있는 객체 (Resource 요소), 액세스 할 수있는 방법 (Action 요소)을 정의 할 수 있습니다. 버킷 수준에서 버킷 정책을 적용하면 여러 정책을 사용하여 액세스를 제어함으로써 버킷 내부의 여러 객체에 대한 세분화 된 액세스를 정의 할 수 있습니다. 버킷 정책을 검토하여 S3 버킷의 객체에 액세스 할 수있는 사용자를 확인할 수도 있습니다.

- **S3 버킷 객체에 대한 프로그래밍 방식 전용 액세스를 위해 ACL (액세스 제어 목록) 및 IAM 정책** 사용-ACL이 IAM 및 S3 버킷 정책보다 요구 사항을 더 잘 충족하는 경우에만 객체 ACL을 사용하여 특정 시나리오에 대한 권한을 관리합니다. Amazon S3 ACL을 사용하면 사용자가 READ, WRITE, READ_ACP, WRITE_ACP 및 FULL_CONTROL의 권한 집합 만 정의 할 수 있습니다. Amazon S3 ACL에 대한 피부 여자로 AWS 계정 또는 사전 정의 된 Amazon S3 그룹 중 하나만 사용할 수 있습니다.

- **S3 버킷 객체에 대한 프로그래밍 방식 및 콘솔 액세스를 위해 교차 계정 IAM 역할 사용** -모든 AWS 서비스가 리소스 기반 정책을 지원하는 것은 아닙니다. 즉, 여러 서비스에 대한 교차 계정 액세스를 제공 할 때 교차 계정 IAM 역할을 사용하여 권한 관리를 중앙 집중화 할 수 있습니다. 교차 계정 IAM 역할을 사용하면 여러 S3 버킷에 저장된 S3 객체에 대한 교차 계정 액세스 프로비저닝을 단순화하여 S3 버킷에 대한 여러 정책을 관리 할 필요가 없습니다. 이 방법은 다른 AWS 계정 또는 AWS 서비스에서 소유하거나 업로드 한 객체에 대한 교차 계정 액세스를 허용합니다. 교차 계정 IAM 역할을 사용하지 않는 경우 객체 ACL을 수정해야합니다.

---

- **AWS Organizations 서비스 제어 정책 (SCP)** 
  
  - AWS Organizations 서비스 제어 정책 (SCP)을 사용하여 조직 또는 조직 구성 단위 (OU)의 계정 구성원에 대한 최대 권한을 정의합니다. SCP는 자격 증명 기반 정책 또는 리소스 기반 정책이 계정 내의 엔터티 (사용자 또는 역할)에 부여하는 권한을 제한하지만 권한을 부여하지는 않습니다.
- **권한 경계** 
  
  - 권한 경계는 IAM 엔터티 (사용자 또는 역할)에 사용되는 관리 형 정책입니다. 정책은 자격 증명 기반 정책이 엔터티에 부여 할 수있는 최대 권한을 정의하지만 권한을 부여하지는 않습니다.
- **ACL (액세스 제어 목록)** 
- ACL을 사용하여 ACL이 연결된 리소스에 액세스 할 수있는 다른 계정의 보안 주체를 제어합니다. ACL은 JSON 정책 문서 구조를 사용하지 않는 유일한 정책 유형이지만 리소스 기반 정책과 유사합니다. ACL은 지정된 보안 주체에게 권한을 부여하는 교차 계정 권한 정책입니다.
- **리소스 기반 정책** 

  - 소스 기반 정책은 정책에 지정된 보안 주체에 권한을 부여합니다. 주도자는 자원과 동일한 계정 또는 다른 계정에있을 수 있습니다. 리소스 기반 정책의 가장 일반적인 예는 Amazon S3 버킷 정책 및 IAM 역할 신뢰 정책입니다.
- **자격 증명 기반 정책** 

  - IAM 자격 증명 (사용자, 사용자가 속한 그룹 또는 역할)에 관리 형 및 인라인 정책을 연결하는 데 도움이됩니다. 자격 증명 기반 정책은 자격 증명에 권한을 부여합니다.
- **CloudFront 키 페어** 

  - IAM 사용자는 CloudFront 키 페어를 생성 할 수 없습니다. 키 쌍을 생성하려면 루트 자격 증명을 사용하여 로그인해야합니다.

  - 서명 된 URL 또는 서명 된 쿠키를 만들려면 서명자가 필요합니다. 서명자는 CloudFront에서 생성 한 신뢰할 수있는 키 그룹이거나 CloudFront 키 페어가 포함 된 AWS 계정입니다. AWS는 CloudFront 키 페어를 사용하는 대신 서명 된 URL 및 서명 된 쿠키가있는 신뢰할 수있는 키 그룹을 사용하는 것이 좋습니다.
- **EC2 인스턴스 키 페어-SSH** 를 사용하여 Linux 인스턴스에 로그인하는 경우처럼 키 페어를 사용하여 Amazon EC2 인스턴스에 액세스합니다. 이러한 키 페어는 IAM 사용자 로그인에서 생성 할 수 있으며 루트 사용자 액세스가 필요하지 않습니다.
- **IAM 사용자 액세스 키** 

  - 액세스 키는 액세스 키 ID와 보안 액세스 키의 두 부분으로 구성됩니다. AWS CLI 명령 (SDK 사용)을 사용하거나 AWS API 작업을 사용하는 경우 액세스 키를 사용하여 AWS에 보내는 프로그래밍 방식 요청에 서명합니다. IAM 사용자는 자신의 액세스 키를 생성 할 수 있으며 루트 액세스가 필요하지 않습니다.
- **IAM 사용자 암호** 

  - 모든 IAM 사용자는 자신의 자격 증명에 액세스 할 수 있으며 필요할 때마다 암호를 재설정 할 수 있습니다.
-  **ECS는 Docker 컨테이너를 실행하는 데 사용되며 3 가지 특징이 있습니다.**

  - ECS "Classic": 컨테이너를 실행할 EC2 인스턴스 프로비저닝
  - Fargate : ECS 서버리스, 프로비저닝 할 EC2 더 이상 없음
  - EKS : AWS의 관리 형 Kubernetes
- **IAM 콘솔의 Access Advisor 기능** 

  - <u>사용하지 않는 역할을 식별하는 데 도움을주기 위해 IAM은 역할이 AWS 요청에 마지막으로 사용 된 시간을 나타내는 마지막 사용 타임 스탬프를보고합니다. 보안 팀은이 정보를 사용하여 사용하지 않는 역할을 식별하고 분석 한 다음 확실하게 제거 할 수 있습니다. 이를 통해 AWS 환경의 보안 태세를 개선 할 수 있습니다.</u> 또한 사용하지 않는 역할을 제거하면 사용중인 역할에만 집중하여 모니터링 및 감사 작업을 단순화 할 수 있습니다.
- **AWS Trusted Advisor** 

  - AWS Trusted Advisor는 비용 최적화, 보안, 내결함성, 서비스 제한 및 성능 향상에 대한 AWS 모범 사례에 따라 리소스를 프로비저닝하는 데 도움이되는 실시간 지침을 제공하는 온라인 도구입니다.
- **IAM Access Analyzer** 

  - <u>**AWS IAM Access Analyzer**는 외부 엔터티와 공유되는 Amazon S3 버킷 또는 IAM 역할과 같은 조직 및 계정의 리소스를 식별하는 데 도움이됩니다.</u> 이를 통해 보안 위험이되는 리소스 및 데이터에 대한 의도하지 않은 액세스를 식별 할 수 있습니다.
    <u>Analyzer의 범위를 조직 또는 AWS 계정으로 설정할 수 있습니다.</u> 이것이 여러분의 신뢰 영역입니다. Analyzer는 신뢰 영역 내에서 지원되는 모든 리소스를 검색합니다. Access Analyzer는 신뢰 영역 외부에서 리소스에 대한 액세스를 허용하는 정책을 찾으면 활성 결과를 생성합니다.
- **Amazon Inspector** 

  - Amazon Inspector는 AWS에 배포 된 애플리케이션의 보안 및 규정 준수를 개선하는 데 도움이되는 자동화 된 보안 평가 서비스입니다. Amazon Inspector는 애플리케이션의 노출, 취약성 및 모범 사례의 편차를 자동으로 평가합니다.
- **AWS Systems Manager Parameter Store**

  - **AWS Systems Manager Parameter Store**는 <u>구성 데이터 관리</u> 및 <u>비밀 관리</u>를위한 <u>안전한 계층적 스토리지를 제공</u>합니다. 암호, 데이터베이스 문자열, Amazon 머신 이미지 (AMI) ID 및 라이선스 코드와 같은 데이터를 파라미터 값으로 저장할 수 있습니다. 값을 일반 텍스트 또는 암호화 된 데이터로 저장할 수 있습니다.
    AWS CloudTrail은 Systems Manager에서 사용자, 역할 또는 AWS 서비스가 수행 한 작업 기록을 제공합니다. AWS CloudTrail에서 수집 한 정보를 사용하여 Systems Manager에 대한 요청, 요청을 한 IP 주소, 요청한 사람, 요청한시기 및 추가 세부 정보를 확인할 수 있습니다.
- **매개 변수**

  - 파라미터를 사용하면 스택을 생성하거나 업데이트 할 때마다 CloudFormation 템플릿에 사용자 지정 값을 입력 할 수 있습니다.

#### S3

Amazon은 다음 사용 사례에 멀티 파트 업로드를 사용할 것을 권장합니다.

안정적인 고 대역폭 네트워크를 통해 큰 개체를 업로드하는 경우 멀티 스레드 성능을 위해 개체 부분을 병렬로 업로드하여 사용 가능한 대역폭의 사용을 최대화하려면 멀티 파트 업로드를 사용하십시오.

불안정한 네트워크를 통해 업로드하는 경우 멀티 파트 업로드를 사용하여 업로드 다시 시작을 방지하여 네트워크 오류에 대한 복원력을 높입니다.

**대용량 파일** 에는 **멀티 파트 업로드를 사용해야합니다** . 일반적으로 개체 크기가 100MB에 도달하면 한 번의 작업으로 개체를 업로드하는 대신 멀티 파트 업로드를 사용하는 것이 좋습니다.

- **직접 Firehose 대상인 Amazon Simple Storage Service (Amazon S3)-Amazon** S3 대상의 경우 스트리밍 데이터가 S3 버킷으로 전달됩니다. 데이터 변환이 활성화 된 경우 선택적으로 소스 데이터를 다른 Amazon S3 버킷에 백업 할 수 있습니다.
- **Amazon S3가 포함 된** Amazon Redshift-Amazon Redshift 대상의 경우 스트리밍 데이터가 먼저 S3 버킷으로 전송됩니다. 그런 다음 Kinesis Data Firehose는 Amazon Redshift COPY 명령을 실행하여 S3 버킷에서 Amazon Redshift 클러스터로 데이터를로드합니다. 데이터 변환이 활성화 된 경우 선택적으로 소스 데이터를 다른 Amazon S3 버킷에 백업 할 수 있습니다.

- **S3 객체 잠금** 

  - <u>S3 객체 잠금을 사용하면 WORM ( "Write Once Read Many") 모델을 사용하여 객체를 저장할 수 있습니다.</u> S3 Object Lock은 우발적이거나 부적절한 데이터 삭제를 방지하는 데 도움이 될 수 있습니다.

- **S3 분석** 

  - <u>Amazon S3 분석 스토리지 클래스 분석을 사용하면 스토리지 액세스 패턴을 분석하여 올바른 데이터를 올바른 스토리지 클래스로 전환 할 시기를 결정할 수 있습니다.</u> S3 Analytics를 사용하여 S3 리소스에 대한 의도하지 않은 액세스를 식별 할 수 없습니다.


- **액세스가 필요한 리소스와 미리 서명 된 URL 공유** -기본적으로 모든 개체는 비공개이며 개체 소유자는 개체에 액세스 할 수 있습니다. 그러나 개체 소유자는 자체 보안 자격 증명을 사용하여 미리 서명 된 URL을 만들어 개체를 다운로드 할 수있는 시간 제한 권한을 부여함으로써 다른 사용자와 개체를 선택적으로 공유 할 수 있습니다. 객체에 대해 사전 서명 된 URL을 생성 할 때 보안 자격 증명을 제공하고, 버킷 이름, 객체 키를 지정하고, HTTP 메서드 (객체를 다운로드하기위한 GET), 만료 날짜 및 시간을 지정해야합니다. 미리 서명 된 URL은 지정된 기간 동안 만 유효합니다.

---

- 
  <img src="https://user-images.githubusercontent.com/76925694/110321525-21a57880-8055-11eb-89ef-0b9ed587c26f.png" alt="image" style="zoom: 67%;" />

  <img src="https://user-images.githubusercontent.com/76925694/110321312-d8edbf80-8054-11eb-9920-336e53464fd3.png" alt="image" style="zoom:80%;" />
  선택적 조건 섹션에는 엔터티가 생성되거나 구성되는 상황을 정의하는 문이 포함되어 있습니다. 예를 들어 <u>조건</u>을 생성 한 다음이를 리소스 또는 출력과 연결하여 AWS CloudFormation이 조건이 참인 경우에만 <u>리소스</u> 또는 <u>출력</u>을 생성하도록 할 수 있습니다.테스트 환경과 프로덕션 환경과 같이 다른 컨텍스트에서 리소스를 생성 할 수있는 템플릿을 재사용하려는 경우 조건을 사용할 수 있습니다. 템플릿에서 prod 또는 test를 입력으로 허용하는 EnvironmentType 입력 매개 변수를 추가 할 수 있습니다. 프로덕션 환경의 경우 특정 기능이있는 Amazon EC2 인스턴스를 포함 할 수 있습니다. 그러나 테스트 환경의 경우 비용을 절약하기 위해 감소 된 기능을 사용하려고합니다.

  매개 변수 섹션에서는 조건을 사용할 수 없습니다. 모든 조건을 정의한 후에는 템플릿의 리소스 및 출력 섹션에서만 리소스 및 리소스 속성과 연결할 수 있습니다.
  **리소스**

  - 리소스 섹션에서는 AWS CloudFormation 스택에서 프로비저닝하려는 리소스를 설명합니다. 조건부로 생성하려는 리소스와 조건을 연결할 수 있습니다.

  **조건** 

  - 실제로 CloudFormation 템플릿의이 섹션에서 조건을 정의합니다.

  **출력**

  - 선택적 출력 섹션은 다른 스택으로 가져 오거나 (교차 스택 참조를 생성하기 위해) 응답으로 반환하거나 (스택 호출을 설명하기 위해) AWS CloudFormation 콘솔에서 볼 수있는 출력 값을 선언합니다. 예를 들어 스택의 S3 버킷 이름을 출력하여 버킷을 더 쉽게 찾을 수 있습니다. 조건부로 생성하려는 출력과 조건을 연결할 수 있습니다.

- **고객 제공 키를 사용한 서버 측 암호화 (SSE-C)**

  - Amazon S3에서 저장 데이터를 보호하기위한 다음과 같은 옵션이 있습니다.

    - 서버 측 암호화
      - Amazon S3에 객체를 데이터 센터의 디스크에 저장하기 전에 암호화하도록 요청한 다음 객체를 다운로드 할 때 해독합니다.
    - 클라이언트 측 암호화 
      - 클라이언트 측 데이터를 암호화하고 암호화 된 데이터를 Amazon S3에 업로드합니다. 이 경우 암호화 프로세스, 암호화 키 및 관련 도구를 관리합니다.

    <u>주어진 사용 사례에 대해 회사는 사용자 지정 애플리케이션을 통해 암호화 키를 관리하고 S3가 암호화를 관리 하도록 하려고합니다. 따라서 SSE-C (고객 제공 키와 함께 서버 측 암호화)를 사용해야합니다.</u>

- **CNAME 레코드 만들기**

  - CNAME 레코드는 acme.example.com과 같은 현재 레코드의 이름에 대한 DNS 쿼리를 다른 도메인 (example.com 또는 example.net) 또는 하위 도메인 (acme.example.com 또는 zenith.example.org)에 매핑합니다.
    <u>CNAME 레코드는 한 도메인 이름을 다른 도메인 이름에 매핑하는 데 사용할 수 있습니다.</u> DNS 프로토콜을 사용하면 영역 정점이라고도하는 DNS 네임 스페이스의 최상위 노드에 대한 CNAME 레코드를 만들 수 없다는 점에 유의해야합니다. 예를 들어 DNS 이름 example.com을 등록하면 zone apex는 example.com입니다. example.com에 대한 CNAME 레코드는 만들 수 없지만 www.example.com, newproduct.example.com 등에 대한 CNAME 레코드는 만들 수 있습니다.

- **Config** 

  - AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가할 수있는 서비스입니다. Config를 사용하면 AWS 리소스 간의 구성 및 관계 변경 사항을 검토하고 자세한 리소스 구성 기록을 살펴보고 내부 지침에 지정된 구성에 대한 전반적인 규정 준수 여부를 결정할 수 있습니다. Config를 사용하여 "xyz 시점에서 내 AWS 리소스가 어떻게 생겼습니까?"와 같은 질문에 답할 수 있습니다. 구성은 KMS API 호출의 소스를 결정하는 데 도움이되지 않습니다.

- **액세스가 필요한 모든 사용자에 대해 Billing and Cost Management 콘솔에 대한 IAM 사용자 액세스를 활성화해야합니다** 

- **CodeCommit 용 IAM에서 지원하는 자격 증명 유형**

  - **Git 자격 증명** 
    - <u>HTTPS를 통해 CodeCommit 리포지토리와 통신하는 데 사용</u>할 수있는 IAM 생성 사용자 이름 및 암호 쌍입니다.
  - **SSH 키** 
    - <u>SSH를 통해 CodeCommit 리포지토리와 통신하기 위해 IAM 사용자와 연결</u>할 수있는 로컬로 생성 된 퍼블릭-프라이빗 키 페어입니다.
  - **AWS 액세스 키** 
    - <u>AWS CLI에 포함 된 자격 증명 도우미와 함께 이러한 키를 사용하여 HTTPS를 통해 CodeCommit 리포지토리와 통신</u> 할 수 있습니다.

- **EC2 인스턴스 비용**

  - AWS에 따르면 AWS 계정이 12 개월 미만인 경우 특정 사용 제한 내에서 무료로 t2.micro 인스턴스를 사용할 수 있습니다.


#### **KMS**

- **KMS는 CMK를 저장하고 클라이언트로부터 데이터를 수신하여 암호화하고 다시 보냅니다.**

  - 고객 마스터 키 (CMK)는 마스터 키의 논리적 표현입니다. CMK에는 키 ID, 생성 날짜, 설명 및 키 상태와 같은 메타 데이터가 포함됩니다. CMK에는 데이터를 암호화하고 해독하는 데 사용되는 키 자료도 포함되어 있습니다. KMS, AWS CloudHSM 클러스터에서 CMK를 생성하거나 키 관리 인프라에서 가져올 수 있습니다.

    AWS KMS는 대칭 및 비대칭 CMK를 지원합니다. **대칭 CMK**는 암호화 및 암호 해독에 사용되는 256 비트 키를 나타냅니다. 비대칭 CMK는 암호화 및 복호화 또는 서명과 확인 (둘다는 아님)에 사용되는 RSA 키 쌍 또는 서명 및 확인에 사용되는 ECC (타원 곡선) 키 쌍을 나타냅니다.

    AWS KMS는 고객 관리 형 CMK, AWS 관리 형 CMK 및 AWS 소유 CMK의 세 가지 유형의 CMK를 지원합니다.

    KMS는 매번 새 키를 생성하지 않지만 KMS가 키를 교체하도록 할 수 있습니다. 모범 사례는 암호화 키의 광범위한 재사용을 권장하지 않으므로 새 키를 생성하는 것이 좋습니다.

    KMS는 클라이언트에 CMK를 전송하지 않고 KMS 자체가 암호화 한 다음 데이터를 해독합니다.

    자신의 CMK (고객 마스터 키)를 가져올 수 있지만 한 번만 수행하면 필요에 따라 암호화 / 복호화 할 수 있습니다.

- **AWS Key Management Service (SSE-KMS)에 저장된 고객 마스터 키 (CMK)를 사용한 서버 측 암호화**

  Amazon S3에서 저장 데이터를 보호하기위한 다음과 같은 옵션이 있습니다.

  서버 측 암호화 – Amazon S3에 객체를 데이터 센터의 디스크에 저장하기 전에 암호화하도록 요청한 다음 객체를 다운로드 할 때 해독합니다.

  클라이언트 측 암호화 – 클라이언트 측 데이터를 암호화하고 암호화 된 데이터를 Amazon S3에 업로드합니다. 이 경우 암호화 프로세스, 암호화 키 및 관련 도구를 관리합니다.

  AWS KMS (SSE-KMS)에서 서버 측 암호화를 사용하는 경우 기본 AWS 관리 형 CMK를 사용하거나 이미 생성 한 고객 관리 형 CMK를 지정할 수 있습니다.

  고객 관리 형 CMK를 직접 생성하면 CMK를보다 유연하게 제어 할 수 있습니다. 예를 들어 고객 관리 형 CMK를 생성, 교체 및 비활성화 할 수 있습니다. 액세스 제어를 정의하고 데이터를 보호하는 데 사용하는 고객 관리 형 CMK를 감사 할 수도 있습니다.

---

- **스팟 인스턴스** 

  - 스팟 인스턴스는 온 디맨드 가격보다 저렴한 가격으로 제공되는 미사용 EC2 인스턴스입니다. 스팟 인스턴스는 용량을 사용할 수 있고 요청에 대한 시간당 최고 가격이 스팟 가격을 초과 할 때마다 실행됩니다. 사용되지 않은 용량이있는 모든 인스턴스가 할당됩니다. 비용 효율적이지만 클라이언트의 단일 테넌트 하드웨어 요구 사항을 충족하지 못하므로 올바른 옵션이 아닙니다.

- **전용 호스트** 

  - Amazon EC2 전용 호스트는 사용 전용 EC2 인스턴스 용량이있는 물리적 서버입니다. 전용 호스트를 사용하면 EC2 인스턴스에서 기존 소프트웨어 라이선스를 사용할 수 있습니다. 전용 호스트를 사용하면 인스턴스가 서버에 배치되는 방식을 파악하고 제어 할 수 있습니다. 이 옵션은 전용 인스턴스보다 비용이 많이 들기 때문에 현재 요구 사항에 적합한 선택이 아닙니다.

- **온 디맨드 인스턴스** 

  - 온 디맨드 인스턴스를 사용하면 장기 약정없이 컴퓨팅 용량에 대해 초 단위로 비용을 지불합니다. 수명주기를 완전히 제어 할 수 있습니다. 실행, 중지, 최대 절전 모드, 시작, 재부팅 또는 종료시기를 결정합니다. 하드웨어 격리는 불가능하며 온 디맨드는 인스턴스 요금이 가장 많이 부과되므로 현재 요구 사항에 대한 정답이 아닙니다.

- SaaS 회사는 사용자가 전 세계적으로 사용하는 HealthCare 웹 애플리케이션을 실행합니다. 모바일 개발자가 애플리케이션 별 기능을위한 공용 API를 공개하도록 요청했습니다. 모바일 개발자가 제품 오퍼링으로 API를 사용할 수 있도록 결정합니다.

  다음 중 어떤 옵션을 사용할 수 있습니까?

  - **API Gateway 사용량 계획 사용**

    Amazon API Gateway는 규모에 관계없이 REST, HTTP 및 WebSocket API를 생성, 게시, 유지 관리, 모니터링 및 보호하는 AWS 서비스입니다. API 개발자는 AWS 또는 기타 웹 서비스와 AWS 클라우드에 저장된 데이터에 액세스하는 API를 생성 할 수 있습니다.

    사용량 계획은 배포 된 하나 이상의 API 단계 및 메서드에 액세스 할 수있는 사용자와 액세스 할 수있는 양과 속도를 지정합니다. 플랜은 API 키를 사용하여 API 클라이언트를 식별하고 각 키의 관련 API 단계에 대한 액세스를 측정합니다.

    고객이 비즈니스 요구 사항 및 예산 제약을 충족하는 합의 된 요청 속도 및 할당량으로 선택한 API에 액세스 할 수 있도록 사용 계획 및 API 키를 구성 할 수 있습니다.

- **비밀 관리자**

  **AWS Secrets Manager**를 사용하면 수명주기 동안 데이터베이스 자격 증명, API 키 및 기타 비밀을 쉽게 교체, 관리 및 검색 할 수 있습니다. 사용자와 애플리케이션은 Secrets Manager API를 호출하여 비밀을 검색하므로 민감한 정보를 일반 텍스트로 하드 코딩 할 필요가 없습니다. Secrets Manager는 Amazon RDS, Amazon Redshift 및 Amazon DocumentDB에 대한 내장 통합을 통해 비밀 순환을 제공합니다.

- **교차 스택 참조를 생성하고 Export output 필드를 사용하여 네트워크 스택에서 VPC 값에 플래그를 지정합니다. 그런 다음 Fn :: ImportValue 내장 함수를 사용하여 VPC의 값을 웹 애플리케이션 스택으로 가져옵니다.**

  AWS CloudFormation은 개발자와 기업이 관련 AWS 및 타사 리소스 모음을 생성하고이를 질서 있고 예측 가능한 방식으로 프로비저닝 할 수있는 쉬운 방법을 제공합니다.

  <u>교차 스택 참조를 생성하여 한 AWS CloudFormation 스택에서 다른 스택으로 리소스를 내보낼 수 있습니다.</u>예를 들어 VPC와 서브넷이있는 네트워크 스택과 별도의 퍼블릭 웹 애플리케이션 스택이있을 수 있습니다. <u>네트워크 스택의 보안 그룹과 서브넷을 사용하려면 웹 애플리케이션 스택이 네트워크 스택의 리소스 출력을 참조 할 수 있도록하는 교차 스택 참조를 생성 할 수 있습니다.</u> 교차 스택 참조를 사용하면 웹 애플리케이션 스택의 소유자가 네트워킹 규칙 또는 자산을 생성하거나 유지할 필요가 없습니다.

  크로스 스택 참조를 생성하려면 내보내기 출력 필드를 사용하여 내보낼 리소스 출력 값에 플래그를 지정합니다. 그런 다음 Fn :: ImportValue 내장 함수를 사용하여 값을 가져옵니다. Ref 내장 함수를 사용하여 값을 가져올 수 없습니다.

- 다음 중 AWS 계정 루트 사용자 만 생성 할 수있는 보안 자격 증명은 무엇입니까?

  - **CloudFront 키 페어** 

    - IAM 사용자는 CloudFront 키 페어를 생성 할 수 없습니다. 키 쌍을 만들려면 루트 자격 증명을 사용하여 로그인해야합니다.

    서명 된 URL 또는 서명 된 쿠키를 만들려면 서명자가 필요합니다. 서명자는 CloudFront에서 생성 한 신뢰할 수있는 키 그룹이거나 CloudFront 키 페어가 포함 된 AWS 계정입니다. AWS는 CloudFront 키 페어를 사용하는 대신 서명 된 URL 및 서명 된 쿠키가있는 신뢰할 수있는 키 그룹을 사용하는 것이 좋습니다.
  
- **AWS Organizations 서비스 제어 정책 (SCP)** 

  - AWS Organizations 서비스 제어 정책 (SCP)을 사용하여 조직 또는 조직 구성 단위 (OU)의 계정 구성원에 대한 최대 권한을 정의합니다. SCP는 자격 증명 기반 정책 또는 리소스 기반 정책이 계정 내의 엔터티 (사용자 또는 역할)에 부여하는 권한을 제한하지만 권한을 부여하지는 않습니다.

- **권한 경계** 

  - 권한 경계는 IAM 엔터티 (사용자 또는 역할)에 사용되는 관리 형 정책입니다. 정책은 자격 증명 기반 정책이 엔터티에 부여 할 수있는 최대 권한을 정의하지만 권한을 부여하지는 않습니다.

- 개발자가 방금 EC2 인스턴스에 대한 Application Load Balancer 구성을 완료했습니다. 구성 테스트를 시작했을 때 그는 ALB에 대상 그룹을 할당하지 못했다는 것을 깨달았습니다.

  디버그 로그에서 어떤 오류 코드를 예상해야합니까?

  - **HTTP 503**

    - **HTTP 503**은 '서비스를 사용할 수 없음'오류를 나타냅니다. ALB의 이 오류는 등록 된 대상이 없는 로드 밸런서의 대상 그룹을 나타냅니다.

  - **HTTP 500** 

    - <u>HTTP 500은 '내부 서버'오류를 나타냅니다.</u> 오류에는 몇 가지 이유가 있습니다. 클라이언트가 HTTP 프로토콜없이 요청을 제출했고로드 밸런서가 리디렉션 URL을 생성 할 수 없습니다. 웹 ACL 규칙을 실행하는 동안 오류가 발생했습니다.

    **HTTP 504** 

    - <u>HTTP 504는 '게이트웨이 시간 초과'오류입니다.</u> 이 오류에 대한 몇 가지 이유는 다음과 같습니다. 연결 시간 초과가 만료되기 전에로드 밸런서가 대상에 대한 연결을 설정하지 못했습니다.로드 밸런서가 대상에 대한 연결을 설정했지만 유휴 시간 초과 기간이 경과하기 전에 대상이 응답하지 않았습니다.

    **HTTP 403** 

    - <u>HTTP 403은 '금지'오류입니다.</u> Application Load Balancer에 대한 요청을 모니터링하도록 AWS WAF 웹 ACL (웹 액세스 제어 목록)을 구성했으며 요청을 차단했습니다.

- AWS 계정 내의 EC2 인스턴스에서 실행되는 CMS 애플리케이션을 배포하기 위해 Cloud Formation 템플릿을 생성하고 있습니다. 애플리케이션이 여러 리전에 배포되므로 기본 AMI에 대해 가능한 모든 값의 맵을 생성해야합니다.

  `!FindInMap`이 사용 사례를 수행하기 위해 함수를 어떻게 호출 할 것인가?

- 한 회사의 개발자가 Amazon EC2 인스턴스에 SSH를 사용하기위한 디지털 서명을 생성하려고합니다.

  다음 중이 사용 사례를 용이하게하기 위해 사용할 수있는 엔티티는 무엇입니까?

  - **키 쌍** 
    - <u>키 쌍은 공개 키와 개인 키로 구성됩니다. 프라이빗 키를 사용하여 디지털 서명을 생성하면 AWS는 해당 퍼블릭 키를 사용하여 서명을 검증합니다.</u> <u>키 페어는 Amazon EC2 및 Amazon CloudFront에만 사용됩니다</u>. AWS는 귀하의 계정에 키 페어를 제공하지 않습니다. 작성해야합니다. Amazon EC2 콘솔, CLI 또는 API에서 Amazon EC2 키 페어를 생성 할 수 있습니다. <u>키 쌍은 인스턴스에 안전하게 액세스 할 수있는 강력한 조합을 제공하며 비밀번호를 사용하는 것보다 더 나은 옵션입니다.</u>

- AWS 클라우드에 배포 된 웹 애플리케이션에 대해 HTTPS 연결을 활성화하기 위해 개발자는 서버 인증서를 생성하는 중입니다.

  SSL / TLS 서버 인증서를 배포하는 데 사용할 수있는 AWS 엔터티는 무엇입니까? (2 개 선택)

  - **AWS Certificate Manager** 

    - AWS Certificate Manager (ACM)는 서버 인증서를 프로비저닝, 관리 및 배포하는 데 선호되는 도구입니다. ACM을 사용하면 인증서를 요청하거나 기존 ACM 또는 외부 인증서를 AWS 리소스에 배포 할 수 있습니다. ACM에서 제공하는 인증서는 무료이며 자동으로 갱신됩니다. 지원되는 리전에서는 ACM을 사용하여 콘솔에서 또는 프로그래밍 방식으로 서버 인증서를 관리 할 수 있습니다.

  - **IAM** 

    - IAM은 ACM에서 지원하지 않는 리전에서 HTTPS 연결을 지원해야하는 경우에만 인증서 관리자로 사용됩니다. IAM은 프라이빗 키를 안전하게 암호화하고 암호화 된 버전을 IAM SSL 인증서 스토리지에 저장합니다. IAM은 모든 리전에서 서버 인증서 배포를 지원하지만 AWS에서 사용하려면 외부 공급자로부터 인증서를 받아야합니다. ACM 인증서를 IAM에 업로드 할 수 없습니다. 또한 IAM 콘솔에서 인증서를 관리 할 수 없습니다


#### DynamoDB

- **DynamoDB – 데이터 읽기**

  - Get Item:
    - PK를 기반으로 읽기
    - 기본 키 = HASH 또는 HASH-RANGE
    - 기본적으로 일관된 읽기
    - 강력하게 일관된 읽기(strongly consistent reads)를 사용 하는 옵션(RCU 증가 - 시간이 더 오래 걸릴 수 있음)
    - 특정 속성만 포함하도록 **ProjectionExpression**을 지정할 수 있습니다.
    
  - BatchGetItem:
    - 최대 100개 품목
    - 최대 16MB의 데이터
    - 지연 시간을 최소화하기 위해 항목을 병렬로 검색

  - **`ProjectionExpression`** : 프로젝션 표현식은 원하는 속성을 식별하는 문자열입니다. 단일 속성을 검색하려면 해당 이름을 지정하십시오. 여러 속성의 경우 이름은 쉼표로 구분되어야합니다.

  - **모든 항목에 대해 GetItem 작업을 수행하는 동안 ConsistentRead = true 사용**

    DynamoDB는 최종적으로 일관되고 강력하게 일관된 읽기를 지원합니다.

    최종적으로 일관된 읽기

    DynamoDB 테이블에서 데이터를 읽을 때 응답에 최근 완료된 쓰기 작업의 결과가 반영되지 않을 수 있습니다. 응답에 일부 오래된 데이터가 포함될 수 있습니다. 잠시 후 읽기 요청을 반복하면 응답이 최신 데이터를 반환해야합니다.

    일관된 읽기

    강력한 일관된 읽기를 요청하면 DynamoDB는 성공한 모든 이전 쓰기 작업의 업데이트를 반영하여 최신 데이터가 포함 된 응답을 반환합니다.

    DynamoDB는 기본적으로 최종 일관성 읽기를 사용합니다. 읽기 작업 (예 : GetItem, Query 및 Scan)은 ConsistentRead 매개 변수를 제공합니다. 이 파라미터를 true로 설정하면 DynamoDB는 작업 중에 강력하게 일관된 읽기를 사용합니다. 주어진 사용 사례에 따라 모든 항목의 마지막 업데이트 된 값만 애플리케이션에서 사용되도록하려면 GetItem 작업에 대해 ConsistentRead = true를 설정하여 강력하게 일관된 읽기를 사용해야합니다.
    
  - 새 프로젝트는 각각 크기가 6KB 인 초당 10 회의 강력하게 일관된 읽기의 처리량 요구 사항을 요구합니다.

    하나의 읽기 용량 단위는 최대 4KB 크기의 항목에 대해 초당 하나의 강력한 일관된 읽기를 나타냅니다. 4KB보다 큰 항목을 읽어야하는 경우 DynamoDB는 추가 읽기 용량 단위를 사용해야합니다.

    1) **항목 크기 / 4KB**, 가장 가까운 정수로 반올림합니다.

    따라서 위의 경우 6KB / 4KB = 1.5 또는 2 개의 읽기 용량 단위입니다.

    2) **항목 당 읽기 용량 단위 1 개 (강력한 일관된 읽기 이후) × 초당 읽기 수**

    따라서 위의 경우 2 x 10 = 20 읽기 용량 단위입니다.

- **ElastiCache**
  **Amazon S3를 백업으로 사용하는** Amazon ElastiCache-Amazon ElastiCache는 Redis 또는 Memcached와 호환되는 완전 관리 형 인 메모리 데이터 스토어입니다.

- **Amazon Elasticsearch Service (Amazon ES)**

  **Amazon S3에 데이터를 선택적으로 백업하는 Amazon Elasticsearch Service (Amazon ES)-Amazon** ES는 Kinesis Firehose에 지원되는 대상 유형입니다. 스트리밍 데이터는 Amazon ES 클러스터로 전달되며 선택적으로 S3 버킷에 동시에 백업 할 수 있습니다.
  
- **AWS CLI --dry-run 옵션 사용** : --dry-run 옵션은 실제로 요청하지 않고 작업에 필요한 권한이 있는지 확인하고 오류 응답을 제공합니다. 필요한 권한이있는 경우 오류 응답은 DryRunOperation이고, 그렇지 않으면 UnauthorizedOperation입니다.

- **EC2 메타 데이터 서비스를 사용하여 정책** 을 검색 **하고 IAM 정책 시뮬레이터를 사용합니다.** EC2 메타 데이터 서비스는 instance-id, local-hostname, public-hostname과 같은 동적 정보를 검색하는 데 사용됩니다.

- **Amazon Athena**
  Amazon Athena는 표준 SQL을 사용하여 Amazon S3의 데이터를 쉽게 분석 할 수있는 대화 형 쿼리 서비스입니다. Athena는 서버리스이므로 관리 할 인프라가 없으며 실행 한 쿼리에 대해서만 비용을 지불합니다. 데이터베이스 트랜잭션을 관리하는 데 사용할 수 없습니다.

- **Amazon Redshift**
  Amazon Redshift는 대규모 데이터 세트 저장 및 분석을 위해 설계된 완전 관리 형 페타 바이트 규모의 클라우드 기반 데이터웨어 하우스 제품입니다. 데이터베이스 트랜잭션을 관리하는 데 사용할 수 없습니다.

- DynamoDB에는 Amazon S3에 쓰는 두 가지 기본 백업 방법 (온 디맨드, 특정 시점 복구)이 있지만 이러한 백업에 사용되는 S3 버킷에는 액세스 할 수 없습니다.
- **AWS Data Pipeline을 사용하여 테이블을 선택한 계정의 S3 버킷으로 내보내고 로컬에서 다운로드** 하는 것이 가장 쉬운 방법입니다. 이 방법은 가능한 가장 적은 양의 AWS 리소스를 사용하여 일회성 백업을 수행하려는 경우에 사용됩니다. Data Pipeline은 Amazon EMR을 사용하여 백업을 생성하고 스크립팅이 자동으로 수행됩니다. 이 작업을 수행하기 위해 Apache Hive 또는 Apache Spark를 배울 필요는 없습니다.
- **Amazon EMR과 함께 Hive를 사용하여 데이터를 S3 버킷** 으로 내보내고 **로컬로 다운로드-Hive를 사용하여 데이터를 S3 버킷** 으로 내 보냅니다. 또는 오픈 소스 emr-dynamodb-connector를 사용하여 Spark 또는 Hive에서 사용자 지정 백업 방법을 관리합니다. 이러한 방법은 활성 Amazon EMR 사용자이고 Hive 또는 Spark에 익숙한 경우 사용하는 모범 사례입니다. 이러한 방법은 데이터 파이프 라인 방법보다 더 많은 제어를 제공합니다.
- **AWS Glue를 사용하여 테이블을 Amazon S3에 복사하고 로컬로 다운로드** -AWS Glue를 사용하여 테이블을 Amazon S3에 복사합니다. 이는 Amazon Athena와 같은 다른 서비스에서도 사용할 수있는 자동화 된 연속 백업을 원하는 경우 사용하는 모범 사례입니다.

---

### EBS 볼륨 타입

시험에 많이 나옴. 각 타입별 특징을 익혀두길

- **SSD 군**
  - General Purpose SSD (GP2)
    - 다양한 워크로드에 대해 가격과 성능이 균형을 이루는 범용 SSD 볼륨
    - 최대 10K IOPS 지원
    - 1GB당 3IOPS속도가 나옴
    - 가장 많이 사용 (성능면에서나 가격 면에서 합리적)
    - Boot Volume으로 사용 가능
    - 사용 사례
      - 대부분의 워크로드
      - 시스템 부팅 볼륨
      - 가상 데스크톱
      - 지연 시간이 짧은 대화 형 앱
      - 개발 및 테스트 환경
    - 1GiB-16TiB
    - 작은 GP2 볼륨은 IOPS를 3,000으로 버스트 할 수 있음
    - 최대 IOPS는 16,000
    - GB당 3IOPS. 즉, **5334GB가 최대 IOPS**임을 의미
    - **5.3 TiB 크기** - 일반 용도의 SSD는 (GP2) 볼륨은 다양한 작업에 이상적입니다 비용 효율적인 스토리지를 제공합니다. 이러한 볼륨은 한 자릿수 밀리 초의 지연 시간과 장시간 동안 3,000 IOPS까지 버스트 할 수있는 기능을 제공합니다. 최소 100IOPS (33.33GiB 이하)와 최대 16,000IOPS (5,334GiB 이상) 사이에서 기준 성능은 볼륨 크기의 GiB 당 3IOPS로 선형 적으로 확장됩니다.
  - Provisioned IOPS SSD (IO1)
    - 미션 크리티컬 한 저 지연 또는 높은 처리량 워크로드를 위한 고성능 SSD 볼륨
      - 미션 크리티컬 : 사업이나 조직의 생존에 필수적인 것
    - 극도의 I/O률을 요구하는 환경에서 주로 사용 됨
      - 예: 매우 큰 DB 관리
    - 10K 이상의 IOPS를 지원
    - Boot Volume으로 사용 가능
    - 사용 사례
      - 지속적인 IOPS 승능 또는 볼륨당 16,000 IOPS(GP2의 제한 값)이상이 필요한 중요 비즈니스 애플리케이션
      - 다음과 같은 대규모 데이터베이스 워크로드
        - MongoDB
        - Cassandra
        - Microsoft SQL Server
        - MySQL Server
        - PostgreSQL
        - Oracle
    - 4GiB-16TiB
    - IOPS가 프로비저닝 됨(PIOPS) - MIN 100-MAX 64,000 (Nitro 인스턴스) 기타 MAX 32,000 (기타 인스턴스)
    - 요청된 볼륨 크기 (GiB 단위)에 대한 프로비저닝 된 IOPS의 최대 비율은 50:1
- **Magnetic/HDD군**
  - Throughput Optimized Hdd (ST1)
    - 자주 액세스 하고 처리량이 많은 워크로드를 위해 설계된 저렴한 HDD 볼륨
    - 주로 사용
      - 빅데이터 Datawarehouse (빅데이터 보관)
      - Log 프로세싱 (로그파일 보관)
    - Boot volume으로 사용 불가능
      - Windows10과 같은 운영체제를 가질 수 없음
    - 사용 사례
      - 저렴한 가격으로 일관되고 빠른 처리량이 필요한 스트리밍 워크로드
      - 빅 데이터, 데이터 웨어 하우스, 로그 처리
      - Apache Kafka
    - 500GiB-16TiB
    - 최대 IOPS는 500
    - 500MiB/s의 최대 처리량 - 버스트 가능
  - CDD HDD (SC1)
    - 액세스 빈도가 낮은 워크로드를 위해 설계된 최저 비용 HDD 볼륨
    - 파일 서버와 같이 드문 Volume 접근 시 주로 사용
      - 빈번한 입출력이 없고, 오랫동안 보관해도 괜찮은 데이터를 보관할 때 사용
    - Boot volume으로 사용 불가능
    - 비용 매우 저렴
    - 사용 사례
      - 자주 액세스 하지 않는 대용량 데이터를 위한 처리량 지향 스토리지
      - 최저 스토리지 비용이 중요한 시나리오
    - 500GiB-16TiB
    - 최대 IOPS는 250
    - 250MiB의 최대 처리량 - 버스트 가능
  - Magnetic (Standard)
    - 디스크 1GB당 가장 싼 비용을 자랑함.
    - Boot volume으로 유일하게 가능 (마그네틱/HDD라인 중)
- EBS 볼륨은 크기 / 처리량 / IOPS(초당 I/O Ops)로 특징 지어 짐
- 확실하지 않다고 생각되는 경우 항상 AWS 설명서를 참조하길
- GP2및 IO1만 부팅 볼륨으로 사용할 수 있음 (마그네틱 제외)

### EBS vs Instance Store

- 일부 인스턴스는 루트 EBS 볼륨과 함께 제공되지 않음
- 대신 '인스턴스 스토어' (= 임시 스토리지)와 함께 제공 됨
- 인스턴스 스토어가 물리적으로 머신에 연결 됨(EBS는 네트워크 드라이브)
- 장점
  - I/O 성능 향상 (EBS gp2의 최대 IOPS는 16000, io1은 64000)
  - 버퍼 / 캐시 / 스크래치 데이터 / 임시 콘텐츠에 적합
  - 재부팅 후에도 데이터 유지
- 단점
  - 중지 또는 종료 시 인스턴스 스토어가 손실 됨
  - 인스턴스 스토어의 크기를 조정할 수 있음
  - 백업은 사용자가 운영해야 함

---

- **AWS CodeCommit** - AWS CodeCommit은 안전한 Git 기반 리포지토리를 호스팅하는 완전 관리 형 소스 제어 서비스입니다. 이를 통해 팀은 안전하고 확장 성이 뛰어난 에코 시스템에서 코드 공동 작업을 쉽게 수행 할 수 있습니다. AWS CodeCommit은 풀 요청, 분기 및 병합을 통해 팀원과 코드를 공동으로 작업하는 데 도움이됩니다. AWS CodeCommit은 리포지토리를 AWS 클라우드의 빌드, 스테이징 및 프로덕션 환경에 가깝게 유지합니다. 전체 애플리케이션 대신 증분 변경 사항을 전송할 수 있습니다. AWS CodeCommit은 모든 Git 명령을 지원하며 기존 Git 도구와 함께 작동합니다. 선호하는 개발 환경 플러그인, 지속적 통합 / 지속적 전달 시스템, 그래픽 클라이언트를 CodeCommit과 함께 계속 사용할 수 있습니다.

- **AWS CodeBuild** - AWS CodeBuild는 소스 코드를 컴파일하고 테스트를 실행하며 배포 할 준비가 된 소프트웨어 패키지를 생성하는 완전 관리 형 지속적 통합 서비스입니다. CodeBuild를 사용하면 자체 빌드 서버를 프로비저닝, 관리 및 확장 할 필요가 없습니다. CodeBuild는 지속적으로 확장되고 여러 빌드를 동시에 처리하므로 빌드가 대기열에 남아 있지 않습니다.



- **동기화 인식**

  Amazon Cognito Sync는 애플리케이션 관련 사용자 데이터의 교차 디바이스 동기화를 지원하는 AWS 서비스 및 클라이언트 라이브러리입니다. 이를 사용하여 자체 백엔드 없이도 모바일 장치와 웹에서 사용자 프로필 데이터를 동기화 할 수 있습니다. 클라이언트 라이브러리는 데이터를 로컬로 캐시하므로 앱이 기기 연결 상태에 관계없이 데이터를 읽고 쓸 수 있습니다. 장치가 온라인 상태 일 때 데이터를 동기화 할 수 있으며 푸시 동기화를 설정 한 경우 업데이트를 사용할 수 있음을 다른 장치에 즉시 알립니다.

- 개발자가 Amazon EC2 Auto Scaling 그룹을 동적으로 확장하도록 구성하고 있습니다. 다음 중 대상 추적 조정 정책의 일부

  - **ASGAverageCPUUtilization-** 대상 추적 조정 정책에 대해 미리 정의 된 지표입니다. 이는 Auto Scaling 그룹의 평균 CPU 사용률을 나타냅니다.
  - **ASGAverageNetworkOut-** 대상 추적 조정 정책에 대해 미리 정의 된 지표입니다. 이는 Auto Scaling 그룹이 모든 네트워크 인터페이스에서 보낸 평균 바이트 수를 나타냅니다.
  - **ALBRequestCountPerTarget-** 대상 추적 조정 정책에 대해 미리 정의 된 메트릭입니다. 이는 Application Load Balancer 대상 그룹에서 대상 당 완료된 요청 수를 나타냅니다.

- AWS Identity and Access Management (**IAM**) 데이터베이스 인증을 사용하여 DB 인스턴스에 인증 할 수 있습니다. 이 인증 방법을 사용하면 DB 인스턴스에 연결할 때 암호를 사용할 필요가 없습니다. 대신 인증 토큰을 사용합니다. 인증 토큰은 Amazon RDS가 요청시 생성하는 고유 한 문자열입니다. 각 토큰의 수명은 15 분입니다. 인증은 IAM을 사용하여 외부에서 관리되므로 데이터베이스에 사용자 자격 증명을 저장할 필요가 없습니다.
  **RDS MySQL** -IAM 데이터베이스 인증은 MySQL 및 PostgreSQL에서 작동합니다.

  **RDS PostGreSQL** -IAM 데이터베이스 인증은 MySQL 및 PostgreSQL에서 작동합니다.

#### RDS

**리전 간 읽기 전용 복제본 사용**

읽기 전용 복제본을 사용하여 원본 DB 인스턴스의 부하를 줄이는 것 외에도 읽기 전용 복제본을 사용하여 프로덕션 DB 환경에 대한 DR 솔루션을 구현할 수 있습니다. 원본 DB 인스턴스가 실패하면 읽기 전용 복제본을 독립 실행 형 원본 서버로 승격 할 수 있습니다. 읽기 전용 복제본은 원본 데이터베이스와 다른 리전에 생성 될 수도 있습니다. 교차 리전 읽기 전용 복제본을 사용하면 리전 가용성 문제가 발생하는 경우 백업 및 실행을 보장 할 수 있습니다.

**단일 AWS 리전에서 백업을 생성하는 다중 AZ 배포에서 Amazon RDS의 자동 백업 기능 활성화**

Amazon RDS는 다중 AZ 배포를 사용하는 DB 인스턴스에 대한 고 가용성 및 장애 조치 지원을 제공합니다. Amazon RDS는 여러 가지 기술을 사용하여 장애 조치 지원을 제공합니다. MariaDB, MySQL, Oracle 및 PostgreSQL DB 인스턴스 용 다중 AZ 배포는 Amazon의 장애 조치 기술을 사용합니다.

Amazon RDS의 자동 백업 기능은 데이터베이스 인스턴스에 대한 특정 시점 복구를 가능하게합니다. Amazon RDS는 데이터베이스 및 트랜잭션 로그를 백업하고 사용자가 지정한 보존 기간 동안 둘 다 저장합니다. 다중 AZ 구성 인 경우 기본에 대한 I / O 영향을 줄이기 위해 대기에서 백업이 발생합니다. 자동 백업은 단일 AWS 리전으로 제한되는 반면 수동 스냅 샷 및 읽기 전용 복제본은 여러 리전에서 지원됩니다.



자동 백업은 단일 AWS 리전으로 제한되는 반면 수동 스냅 샷 및 읽기 전용 복제본은 여러 리전에서 지원됩니다.

**범용 (SSD) 스토리지 대신 RDS 프로비저닝 된 IOPS (SSD) 스토리지 사용**

- **Amazon** RDS 프로비저닝 된 IOPS 스토리지는 빠르고 예측 가능하며 일관된 I / O 성능을 제공하도록 설계된 SSD 지원 스토리지 옵션입니다. 이 스토리지 유형은 RDS 데이터베이스의 성능을 향상 시키지만 이것은 재해 복구 옵션이 아닙니다.

**RDS DB 클러스터의 데이터베이스 복제 기능 사용** 

- 이 옵션은 선택 항목으로 추가되었습니다. 데이터베이스 복제는 RDS가 아닌 Aurora에서만 사용할 수 있습니다.

---

## CloudWatch 란 무엇입니까?

AWS CloudWatch는 하나의 AWS 서비스에 내장 된 모니터링 도구 모음입니다. 이 게시물에서는 CloudWatch의 각 주요 구성 요소를 살펴보고이 유용한 서비스에서 사용할 수있는 지표, 경보, 로그 및 이벤트를 사용하는 이유를 설명합니다. CloudWatch의 다양한면을 살펴보기 전에 CloudTrail에 대해 자세히 알아 보겠습니다.

## AWS CloudTrail이란 무엇입니까?

AWS CloudTrail은 Amazon 환경 내에서 발생한 모든 단일 API 호출의 로그입니다. 각 호출은 이벤트로 간주되며 S3 버킷에 일괄 적으로 기록됩니다. 이러한 [Cloudtrail 이벤트](https://www.gorillastack.com/blog/real-time-events/cloudtrail-event-names/) 는 요청에 대한 세부 정보, 응답, 요청하는 사용자의 ID, API 호출이 AWS 콘솔, CLI, 일부 타사 애플리케이션 또는 기타 AWS 서비스에서 왔는지 여부를 보여줍니다.

## CloudWatch와 CloudTrail의 차이점

CloudWatch는 AWS 서비스 및 리소스의 활동에 중점을두고 상태 및 성능을보고합니다. 반면에 CloudTrail은 AWS 환경 내에서 발생한 모든 작업에 대한 로그입니다.

#### 참고) https://www.gorillastack.com/blog/cost-optimization/cloudtrail-vs-cloudwatch/#:~:text=The%20Difference%20between%20CloudWatch%20and,place%20inside%20your%20AWS%20environment.



---

**Redis 용 Amazon ElastiCache 사용-Amazon ElastiCache를** 사용하여 많은 읽기 작업이 많은 애플리케이션 워크로드 (예 : 소셜 네트워킹, 게임, 미디어 공유 및 Q & A 포털)의 지연 시간과 처리량을 크게 개선 할 수 있습니다. ElastiCache는 종종 밀리 초 지연 시간이 필요한 데이터베이스와 함께 사용됩니다. 현재 시나리오의 경우 데이터로드가 그다지 많지 않으므로 캐싱 레이어가 필요하지 않습니다.



---

![image-20210313134212457](C:\Users\oliver\AppData\Roaming\Typora\typora-user-images\image-20210313134212457.png)

**Amazon S3 클라이언트 초기화를 함수 핸들러 밖으로 이동** -Lambda에 대한 AWS 모범 사례에서는 실행 컨텍스트 재사용을 활용하여 함수 성능을 개선 할 것을 제안합니다. 함수 핸들러 외부에서 SDK 클라이언트 및 데이터베이스 연결을 초기화하고 정적 자산을 / tmp 디렉토리에 로컬로 캐시합니다. 함수의 동일한 인스턴스에서 처리되는 후속 호출은 이러한 리소스를 재사용 할 수 있습니다. 이것은 실행 시간과 비용을 절약합니다. 호출간에 잠재적 인 데이터 유출을 방지하려면 실행 컨텍스트를 사용하여 보안과 관련된 사용자 데이터, 이벤트 또는 기타 정보를 저장하지 마십시오.

잘못된 옵션 :

**환경 변수를 사용하여 운영 매개 변수 전달** -이것은 Lambda에 권장되는 모범 사례 중 하나입니다. 환경 변수를 사용하여 작동 매개 변수를 전달하면 유용한 정보를 하드 코딩하는 것을 방지 할 수 있습니다. 그러나 이것은 컨텍스트 재사용에 대해 이야기하기 때문에 현재 사용 사례에 대한 올바른 대답이 아닙니다.

**함수에 더 많은 RAM 할당-RAM을** 늘리면 프로세스 속도가 빨라집니다. 그러나 현재 질문에서 리뷰어는 컨텍스트 재사용에 대해 구체적으로 언급했습니다. 따라서 이것은 정답이 아닙니다.

**X-Ray 통합 활성화** -AWS X-Ray를 사용하여 애플리케이션의 구성 요소를 시각화하고, 성능 병목 현상을 식별하고, 오류가 발생한 요청 문제를 해결할 수 있습니다. Lambda 함수는 추적 데이터를 X-Ray로 보내고 X-Ray는 데이터를 처리하여 서비스 맵과 검색 가능한 추적 요약을 생성합니다. 이것은 문제 해결에 유용한 도구입니다. 그러나 현재 사용 사례의 경우 수정해야하는 병목 현상을 이미 알고 있으며 이것이 바로 컨텍스트 재사용입니다.

---

- **SSM 매개 변수 저장소 사용**
  - AWS Systems Manager Parameter Store는 구성 데이터 관리 및 비밀 관리를위한 안전한 계층 적 스토리지를 제공합니다. 암호, 데이터베이스 문자열 및 라이센스 코드와 같은 데이터를 매개 변수 값으로 저장할 수 있습니다. 주어진 사용 사례에서 DevOps 팀은 구성이 변경 될 때마다 애플리케이션을 재배포하지 않기 때문에 SSM Parameter Store를 사용하여 구성을 외부에 저장할 수 있습니다.

- **환경 변수 사용** 
  - AWS CLI를 참조하는 경우 환경 변수는 구성 옵션 및 자격 증명을 지정하는 또 다른 방법을 제공하며 스크립팅에 유용하거나 명명 된 프로필을 임시로 기본값으로 설정하는 데 유용 할 수 있습니다. 애플리케이션이 AWS CLI를 실행하고 있지 않습니다.
- **단계 변수 사용 **
  - **API** Gateway의 여러 릴리스 단계를 관리하기 위해 단계 변수를 사용할 수 있습니다. 이것은 여기서 찾고있는 것이 아닙니다.

---

#### ElastiCache

**ElastiCache를 사용하여 읽기가 많은 애플리케이션 워크로드의 지연 시간과 처리량을 개선합니다.**

**ElastiCache를 사용하여 컴퓨팅 집약적 인 워크로드의 성능 향상**

Amazon ElastiCache를 사용하면 AWS 클라우드에서 인 메모리 데이터 스토어를 실행할 수 있습니다. Amazon ElastiCache는 캐싱, 세션 저장소, 게임, 지리 공간 서비스, 실시간 분석 및 대기열과 같은 실시간 사용 사례에 널리 사용됩니다.

Amazon ElastiCache를 사용하면 많은 읽기 작업이 많은 애플리케이션 워크로드 (예 : 소셜 네트워킹, 게임, 미디어 공유 및 Q & A 포털) 또는 컴퓨팅 집약적 인 워크로드 (예 : 추천 엔진)에 대한 지연 시간과 처리량을 크게 향상시킬 수 있습니다. 캐시에서 자주 읽는 개체입니다.

---

#### ETL (Extact-Transform-Load)

워크로드에는 캐싱에 적합하지 않은 대용량 데이터를 읽고 변환하는 작업이 포함됩니다. ETL 워크로드를 용이하게하려면 AWS Glue 또는 Amazon EMR을 사용해야합니다.

#### 복잡한 JSON 쿼리

복잡한 JSON 쿼리는 RDS 또는 Aurora와 같은 관계형 데이터베이스에서 실행할 수 있습니다.